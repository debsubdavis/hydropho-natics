{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read in the excel file from the utils folder\n",
    "- replace the \"D:/Annotation Stuff/\" with \"/Users/debbiesubocz/capstone/Annotation Stuff/\"\n",
    "- try to find the corresponding file name in: \n",
    "- move img files from fo + most recent annotation json to new directory\n",
    "- upload the img + json combo to roboflow in a new roboflow project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the directory for annotations needed for \"Minus\" Iter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the file locations\n",
    "- \"csv_file_path\" is to the csv file created to map the orignal annotations (from 2022?) json files to the correct image files. Original annotations had multiple annotation .json files associated with a single image file. The file at csv_file_path is a table associating the most recent annotation json file with the correct image file.\n",
    "\n",
    "- \"fo_imgs_path\" is the file location where the more recent image files are saved. .wav files were processed to create png files in Nov 2023. Slight differences in the color scheme of the images, but the .json annotations should theoretically translate to these newly processed images since the only difference is in the color\n",
    "\n",
    "- \"final_df_output\" is where the dataframe should be saved after joining the image file names from the files in the \"fo_imgs_path\" directory and the files in the \"csv_file_path\" table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_annot_file_path = '/Users/debbiesubocz/GitReps/hydropho-natics/utils/unique_images_annotations.csv'\n",
    "fo_imgs_path = \"/Volumes/MacFriendly/1Dec2018_28Feb2019/20HzLin/\"\n",
    "\n",
    "final_df_output = 'fo_image_to_og_json.csv'\n",
    "roboflow_directory = \"/Users/debbiesubocz/capstone/for_roboflow_upload\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a data frame for the original annotation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_file_name', 'image_file_path', 'json_file_path'], dtype='object')\n",
      "           image_file_name                                    image_file_path  \\\n",
      "0   20181204T100004-File-8  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
      "1  20181204T113004-File-16  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
      "2  20181204T113004-File-26  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
      "\n",
      "                                      json_file_path  \n",
      "0  /Users/debbiesubocz/capstone/Annotation Stuff/...  \n",
      "1  /Users/debbiesubocz/capstone/Annotation Stuff/...  \n",
      "2  /Users/debbiesubocz/capstone/Annotation Stuff/...  \n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file with file info related to the original annotations\n",
    "df_og = pd.read_csv(og_annot_file_path)\n",
    "\n",
    "df_og['json_file_path'] = df_og['json_file_path'].str.replace('D:/Annotation Stuff/', '/Users/debbiesubocz/capstone/Annotation Stuff/', regex=False)\n",
    "\n",
    "print(df_og.columns)\n",
    "print(df_og.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data frame for the spectrogram image files processed in Nov 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fo_full_file_path', 'fo_file_name'], dtype='object')\n",
      "                                       fo_full_file_path  \\\n",
      "0      /Volumes/MacFriendly/1Dec2018_28Feb2019/20HzLi...   \n",
      "1      /Volumes/MacFriendly/1Dec2018_28Feb2019/20HzLi...   \n",
      "2      /Volumes/MacFriendly/1Dec2018_28Feb2019/20HzLi...   \n",
      "3      /Volumes/MacFriendly/1Dec2018_28Feb2019/20HzLi...   \n",
      "4      /Volumes/MacFriendly/1Dec2018_28Feb2019/20HzLi...   \n",
      "...                                                  ...   \n",
      "39743  /Volumes/MacFriendly/1Dec2018_28Feb2019/20HzLi...   \n",
      "39744  /Volumes/MacFriendly/1Dec2018_28Feb2019/20HzLi...   \n",
      "39745  /Volumes/MacFriendly/1Dec2018_28Feb2019/20HzLi...   \n",
      "39746  /Volumes/MacFriendly/1Dec2018_28Feb2019/20HzLi...   \n",
      "39747  /Volumes/MacFriendly/1Dec2018_28Feb2019/20HzLi...   \n",
      "\n",
      "                    fo_file_name  \n",
      "0         20181204T100004-File-0  \n",
      "1        20181204T100004-File-10  \n",
      "2        20181204T100004-File-11  \n",
      "3        20181204T100004-File-12  \n",
      "4        20181204T100004-File-13  \n",
      "...                          ...  \n",
      "39743     20190225T040004-File-7  \n",
      "39744     20190225T040004-File-8  \n",
      "39745     20190225T040004-File-9  \n",
      "39746   ._20181204T100004-File-0  \n",
      "39747  ._20190128T173004-File-21  \n",
      "\n",
      "[39748 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory path\n",
    "directory_path = fo_imgs_path\n",
    "\n",
    "# List to store file names\n",
    "full_file_paths = []\n",
    "file_names = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for entry in os.listdir(directory_path):\n",
    "    # Check if it's a file and not a directory\n",
    "    # if os.path.isfile(os.path.join(directory_path, entry)):\n",
    "    #     file_names.append(entry)\n",
    "\n",
    "    full_path = os.path.join(directory_path, entry)\n",
    "    # Check if it's a file and not a directory\n",
    "    if os.path.isfile(full_path):\n",
    "        full_file_paths.append(full_path)\n",
    "        file_names.append(entry)\n",
    "\n",
    "# Print the list of file names\n",
    "# print(file_names[0])\n",
    "        \n",
    "df_fo = pd.DataFrame({'fo_full_file_path': full_file_paths, 'fo_file_name': file_names})\n",
    "df_fo['fo_file_name'] = df_fo['fo_file_name'].str.replace('_20Hz.png', '', regex=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_fo.columns)\n",
    "print(df_fo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the join operation and publish the results to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unsuccessful joins: 0\n"
     ]
    }
   ],
   "source": [
    "# Perform the join\n",
    "merged_df = pd.merge(df_og, df_fo, left_on='image_file_name', right_on='fo_file_name', how='left')\n",
    "\n",
    "# Create the 'successful join' column\n",
    "merged_df['successful join'] = merged_df['fo_file_name'].notnull()\n",
    "\n",
    "# Select only the required columns\n",
    "final_df = merged_df[['image_file_name', 'fo_file_name', 'json_file_path', 'fo_full_file_path', 'successful join']]\n",
    "\n",
    "# Display the new DataFrame\n",
    "#print(final_df)\n",
    "unsuccessful_joins = (~final_df['successful join']).sum()\n",
    "\n",
    "# Print the count of unsuccessful joins\n",
    "print(f\"Number of unsuccessful joins: {unsuccessful_joins}\")\n",
    "\n",
    "# Write DataFrame to CSV file\n",
    "# final_df.to_csv(final_df_output, index=False)\n",
    "\n",
    "# print(f\"DataFrame saved to '{final_df_output}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_file_name', 'fo_file_name', 'json_file_path',\n",
      "       'fo_full_file_path', 'successful join'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(final_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move the files to a new directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to move files to new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied successfully.\n"
     ]
    }
   ],
   "source": [
    "# Directory where the files will be copied\n",
    "new_directory = roboflow_directory\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(new_directory):\n",
    "    os.makedirs(new_directory)\n",
    "\n",
    "\n",
    "# Function to copy files\n",
    "def copy_files(file_paths):\n",
    "    for file_path in file_paths:\n",
    "        if os.path.exists(file_path):\n",
    "            shutil.copy(file_path, new_directory)\n",
    "\n",
    "\n",
    "#file_paths_test = [\"/Users/debbiesubocz/capstone/test_labeling/20181205T203004-File-10.png\", \"/Users/debbiesubocz/capstone/test_labeling/20181205T203004-File-10.json\"]\n",
    "\n",
    "copy_files(final_df['fo_full_file_path'])\n",
    "copy_files(final_df['json_file_path'])\n",
    "\n",
    "print(\"Files copied successfully.\")\n",
    "\n",
    "#copy_files(file_paths_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrophonatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
