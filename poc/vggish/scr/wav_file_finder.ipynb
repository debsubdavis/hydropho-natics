{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404a30d1",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "The purpose of this code is to find all the wav files which contain known, annotated sounds if possible. The main steps we will follow are:\n",
    "\n",
    "1. Read in all the annotated JSON from the 4 different files of annotated JSONs\n",
    "2. Get the labels of the sounds, where in the image they are, and what image they correspond to\n",
    "3. Attempt to match the spectrograms with the wav files that generated them\n",
    "4. Create a file with the label, location in image, image name, wav file name for recordkeeping purposes\n",
    "\n",
    "We'll start by importing some Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eda72cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e4347",
   "metadata": {},
   "source": [
    "Now we will pull the information from the annotated JSON stored in raw_data so we can get data labels, sound coordinates, and image file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a20977d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sound                                             points  \\\n",
      "0  mooring  [[322.18518518518516, 592.1111111111111], [388...   \n",
      "1  mooring  [[979.8328328328328, 549.1481481481482], [1054...   \n",
      "2  mooring  [[1865.8888888888887, 611.3703703703703], [191...   \n",
      "3  mooring  [[737.9879518072288, 739.7831325301204], [821....   \n",
      "4  mooring  [[1975.3373493975903, 919.301204819277], [2034...   \n",
      "\n",
      "                   image_name  \n",
      "0  20181204T100004-File-0.png  \n",
      "1  20181204T100004-File-0.png  \n",
      "2  20181204T100004-File-0.png  \n",
      "3  20181204T100004-File-1.png  \n",
      "4  20181204T100004-File-1.png  \n"
     ]
    }
   ],
   "source": [
    "#Creating a df to save the data in\n",
    "annotation_df = pd.DataFrame(columns=['sound','points','image_name'])\n",
    "annotation_df.head()\n",
    "\n",
    "#Getting the path to the JSON files & listing files\n",
    "#path_to_json = '../raw_data/MLFigs_Labeled_Oct_26_Chris/20181204T100004-File-0.json' #test file\n",
    "path_to_json = '../raw_data/MLFigs_Labeled_Oct_26_Chris/'\n",
    "json_file_list = os.listdir(path_to_json)\n",
    "\n",
    "#Iterate through json files to get annotated image info\n",
    "for file in json_file_list:\n",
    "    path_to_file = path_to_json+file\n",
    "    \n",
    "    #Loading the JSON data & turning into dict\n",
    "    annotated_file = open(path_to_file)\n",
    "    annotated_dict = json.load(annotated_file)\n",
    "    #annotated_dict.keys()\n",
    "\n",
    "    #Pulling out the labels, points, and image path\n",
    "    image_name = annotated_dict['imagePath']\n",
    "    if len(annotated_dict['shapes']) > 0:\n",
    "        for shape in annotated_dict['shapes']:\n",
    "            sound = shape['label']\n",
    "            points = shape['points']\n",
    "            annotation_df.loc[len(annotation_df.index)] = [sound, points, image_name]\n",
    "    else:\n",
    "        sound = None\n",
    "        points = None\n",
    "        annotation_df.loc[len(annotation_df.index)] = [sound, points, image_name]\n",
    "\n",
    "#Saving output for future use\n",
    "annotation_df.to_csv('../intermediate_data/annotated_info.csv')\n",
    "    \n",
    "#Examining head of file\n",
    "print(annotation_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076ec28",
   "metadata": {},
   "source": [
    "Now we need to match the annotated spectrograms with the wav files that generated them. We have the \"image_name\" info, everything before the \".png\" (call it XX) will reference a file called XXMetadata. Inside that XXMetadata file there is a \"FileName\" which contains the raw title information which matches to the hydrophone recording title. As an example:\n",
    "\n",
    "    image_name: 20181204T100004-File-0.png\n",
    "    XX: 20181204T100004-File-0\n",
    "    Metadata file: 20181204T100004-File-0Metadata\n",
    "    FileName contained in the Metadata file: 181204-100002-437599-806141979_Spectrograms_20Hz.mat\n",
    "    Hydrophone recording name: 181204-100002-437599-806141979.wav\n",
    "\n",
    "We need those hydrophone recording names so we can make a list of ones we want to copy to our raw_data file for POC testing. \n",
    "\n",
    "You'll see from the .head() printout above that images are repeated. We will start by getting a unique list of images in our annotation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a67f7183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got all 346 images - this will include images with no annotations\n",
      "Dropping 10 images which don't have any sound annotations\n",
      "Images with no annotations successfully dropped\n"
     ]
    }
   ],
   "source": [
    "#Getting unique images\n",
    "unique_images = annotation_df['image_name'].unique()\n",
    "\n",
    "#Checking that got all of the images\n",
    "if len(unique_images) == len(json_file_list):\n",
    "    print(\"Got all {0} images - this will include images with no annotations\".format(len(unique_images)))\n",
    "    print(\"Dropping {0} images which don't have any sound annotations\".format\n",
    "          (len(annotation_df.loc[annotation_df['sound'].isna()])))\n",
    "    annotated_info_df = annotation_df.dropna()\n",
    "    if len(annotated_info_df) == len(annotation_df)-len(annotation_df.loc[annotation_df['sound'].isna()]):\n",
    "        print(\"Images with no annotations successfully dropped\")\n",
    "    else:\n",
    "        print(\"ERROR - did not drop correct number of images with no sounds\")\n",
    "        print(\"PROGRAMMER NEEDS TO CHECK WHY\")\n",
    "else:\n",
    "    print(\"ERROR - pulled {0} unique images when was expecting {1}\".format(\n",
    "        len(unique_images), len(json_file_list)))\n",
    "    print()\n",
    "    #Stripping the png off of the image names\n",
    "    image_names = list(annotation_df['image_name'])\n",
    "    image_start = [name.replace('.png', '') for name in image_names]\n",
    "    set_image_names = set(image_start)\n",
    "\n",
    "    #Stripping the end off of the json files\n",
    "    json_start = [json_name.replace('.json', '') for json_name in json_file_list]\n",
    "    set_json_names = set(json_start)\n",
    "\n",
    "    #Compare the sets\n",
    "    if len(set_image_names) > len(set_json_names):\n",
    "        missing_json = list(set_image_names.difference(set_json_names))\n",
    "        if len(missing_json) > 0:\n",
    "            print(\"The files which have images but not annotation JSONs are:\")\n",
    "            print(missing_json)\n",
    "    if len(set_image_names) < len(set_json_names):\n",
    "        missing_image = list(set_json_names.difference(set_image_names))\n",
    "        if len(missing_image) > 0:\n",
    "            print(\"The files which have annotation JSONs but not images are:\")\n",
    "            print(missing_image)\n",
    "    print()\n",
    "    print(\"CHECK ORIGINAL DATA TO SEE WHY FILES ARE MISSING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c4c4a6",
   "metadata": {},
   "source": [
    "Now we will examine what kinds of sounds and what numbers of sounds we have captured. Ideally each of these sounds will be identified in our vggish algorithm + sounds which occurr between these sounds in the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ddf5d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>airplane</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flow noise</th>\n",
       "      <td>670</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helicopter</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humpback</th>\n",
       "      <td>1208</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mooring</th>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            points  image_name\n",
       "sound                         \n",
       "airplane        31          31\n",
       "fish            57          57\n",
       "flow noise     670         670\n",
       "helicopter      23          23\n",
       "humpback      1208        1208\n",
       "mooring        332         332"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting numbers of sounds\n",
    "annotated_info_df.groupby('sound').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a725a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851210a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
