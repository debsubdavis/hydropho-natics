{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404a30d1",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "The purpose of this code is to find all the wav files which contain known, annotated sounds if possible. The main steps we will follow are:\n",
    "\n",
    "1. Read in all the annotated JSON from the different files of annotated JSONs (total 4, may do less depending on number and size of of files)\n",
    "2. Get the labels of the sounds, where in the image they are, and what image they correspond to\n",
    "3. Attempt to match the spectrograms with the wav files that generated them\n",
    "4. Create a file with the label, location in image, image name, wav file name for recordkeeping purposes\n",
    "\n",
    "We'll start by importing some Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eda72cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e4347",
   "metadata": {},
   "source": [
    "Now we will pull the information from the annotated JSON stored in raw_data so we can get data labels, sound coordinates, and image file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20977d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating a df to save the data in\n",
    "annotation_df = pd.DataFrame(columns=['sound','points','image_name'])\n",
    "annotation_df.head()\n",
    "\n",
    "#Getting the path to the JSON files & listing files\n",
    "#path_to_json = '../raw_data/MLFigs_Labeled_Oct_26_Chris/20181204T100004-File-0.json' #test file\n",
    "path_to_json = '../raw_data/MLFigs_Labeled_Oct_26_Chris/'\n",
    "json_file_list = os.listdir(path_to_json)\n",
    "\n",
    "#Iterate through json files to get annotated image info\n",
    "for file in json_file_list:\n",
    "    path_to_file = path_to_json+file\n",
    "    \n",
    "    #Loading the JSON data & turning into dict\n",
    "    annotated_file = open(path_to_file)\n",
    "    annotated_dict = json.load(annotated_file)\n",
    "    #annotated_dict.keys()\n",
    "\n",
    "    #Pulling out the labels, points, and image path\n",
    "    image_name = annotated_dict['imagePath']\n",
    "    if len(annotated_dict['shapes']) > 0:\n",
    "        for shape in annotated_dict['shapes']:\n",
    "            sound = shape['label']\n",
    "            points = shape['points']\n",
    "            annotation_df.loc[len(annotation_df.index)] = [sound, points, image_name]\n",
    "    else:\n",
    "        sound = None\n",
    "        points = None\n",
    "        annotation_df.loc[len(annotation_df.index)] = [sound, points, image_name]\n",
    "    \n",
    "#Examining head of file\n",
    "print(annotation_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076ec28",
   "metadata": {},
   "source": [
    "Now we need to match the annotated spectrograms with the wav files that generated them. We have the \"image_name\" info, everything before the \".png\" (call it XX) will reference a file called XXMetadata. Inside that XXMetadata file there is a \"FileName\" which contains the raw title information which matches to the hydrophone recording title. As an example:\n",
    "\n",
    "    image_name: 20181204T100004-File-0.png\n",
    "    XX: 20181204T100004-File-0\n",
    "    Metadata file: 20181204T100004-File-0Metadata\n",
    "    FileName contained in the Metadata file: 181204-100002-437599-806141979_Spectrograms_20Hz.mat\n",
    "    Hydrophone recording name: 181204-100002-437599-806141979.wav\n",
    "\n",
    "We need those hydrophone recording names so we can make a list of ones we want to copy to our raw_data file for POC testing. \n",
    "\n",
    "You'll see from the .head() printout above that images are repeated. We will start by getting a unique list of images in our annotation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting unique images\n",
    "unique_images = annotation_df['image_name'].unique()\n",
    "\n",
    "#Checking that got all of the images\n",
    "if len(unique_images) == len(json_file_list):\n",
    "    print(\"Got all {0} images - this will include images with no annotations\".format(len(unique_images)))\n",
    "    print(\"Dropping {0} images which don't have any sound annotations\".format\n",
    "          (len(annotation_df.loc[annotation_df['sound'].isna()])))\n",
    "    annotated_info_df = annotation_df.dropna()\n",
    "    if len(annotated_info_df) == len(annotation_df)-len(annotation_df.loc[annotation_df['sound'].isna()]):\n",
    "        print(\"Images with no annotations successfully dropped\")\n",
    "    else:\n",
    "        print(\"ERROR - did not drop correct number of images with no sounds\")\n",
    "        print(\"PROGRAMMER NEEDS TO CHECK WHY\")\n",
    "else:\n",
    "    print(\"ERROR - pulled {0} unique images when was expecting {1}\".format(\n",
    "        len(unique_images), len(json_file_list)))\n",
    "    print()\n",
    "    #Stripping the png off of the image names\n",
    "    image_names = list(annotation_df['image_name'])\n",
    "    image_start = [name.replace('.png', '') for name in image_names]\n",
    "    set_image_names = set(image_start)\n",
    "\n",
    "    #Stripping the end off of the json files\n",
    "    json_start = [json_name.replace('.json', '') for json_name in json_file_list]\n",
    "    set_json_names = set(json_start)\n",
    "\n",
    "    #Compare the sets\n",
    "    if len(set_image_names) > len(set_json_names):\n",
    "        missing_json = list(set_image_names.difference(set_json_names))\n",
    "        if len(missing_json) > 0:\n",
    "            print(\"The files which have images but not annotation JSONs are:\")\n",
    "            print(missing_json)\n",
    "    if len(set_image_names) < len(set_json_names):\n",
    "        missing_image = list(set_json_names.difference(set_image_names))\n",
    "        if len(missing_image) > 0:\n",
    "            print(\"The files which have annotation JSONs but not images are:\")\n",
    "            print(missing_image)\n",
    "    print()\n",
    "    print(\"CHECK ORIGINAL DATA TO SEE WHY FILES ARE MISSING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c4c4a6",
   "metadata": {},
   "source": [
    "Now we will examine what kinds of sounds and what numbers of sounds we have captured. Ideally each of these sounds will be identified in our vggish algorithm + sounds which occurr between these sounds in the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting numbers of sounds\n",
    "annotated_info_df.groupby('sound').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55954fb",
   "metadata": {},
   "source": [
    "Now we need to match the wav files to the labeled image files. We will do this by pulling each XXMetadata file, retrieving the contained FileName field, and getting the title prior to \"_Spectrogram...\" which will correspond to the WAV file name.\n",
    "\n",
    "We will start by adding the Metadata file names to the annotated_info_df for easy reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the image prefixes\n",
    "image_names = list(annotated_info_df['image_name'])\n",
    "image_start = [name.replace('.png', '') for name in image_names]\n",
    "\n",
    "#Creating all the metadata file names\n",
    "metadata_names = []\n",
    "for image_name in image_start:\n",
    "    metadata_names.append(image_name + 'Metadata')\n",
    "    \n",
    "#Adding the metadata names to the table with annotation info\n",
    "annotated_info_df['Metadata_files'] = metadata_names\n",
    "#annotated_info_df.head()\n",
    "\n",
    "#Saving the file\n",
    "print('Saving png, sound, and metadata file for future use')\n",
    "annotated_info_df.to_csv('../intermediate_data/annotated_info.csv')\n",
    "annotated_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab8174",
   "metadata": {},
   "source": [
    "Now we need to select a sample of data to run the POC on. We need to limit the number of WAV files we store in GH to be ideally less than 1GB and certainly less than 5GB [(source)](https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-large-files-on-github). Examining the wav files on the external hard drive they appear to be ~166MB per file, given there are 1,000MB in a GB, we can add about 6 WAV files to our repo while staying under the 1GB limit. This means we will want to grab the six files with the most annotated images, and with the greatest diversity of annotated images. \n",
    "\n",
    "We want to see the distribution of sounds/wav file by type and graph those results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting sounds/image\n",
    "sound_count_df = annotated_info_df.groupby(['Metadata_files']).count().reset_index().sort_values('sound', ascending=False)\n",
    "sounds_per_image_df = sound_count_df[['Metadata_files','sound']]\n",
    "sounds_per_image_df.columns = ['Metadata_files','total_sound_count']\n",
    "#print(sounds_per_image_df)\n",
    "\n",
    "#Getting counts of individual sounds per image\n",
    "indiv_sound_count_df = annotated_info_df.groupby(['Metadata_files', 'sound']).count().reset_index().sort_values(\n",
    "    'sound', ascending=False)\n",
    "indiv_sounds_per_image_df = indiv_sound_count_df[['Metadata_files','sound','points']]\n",
    "indiv_sounds_per_image_df.columns = ['Metadata_files','sound','spec_sound_count']\n",
    "#print(indiv_sounds_per_image_df)\n",
    "\n",
    "#Joining the total and individual sound count data\n",
    "sound_distro_df = pd.merge(right = sounds_per_image_df, left = indiv_sounds_per_image_df, how='left', on='Metadata_files')\n",
    "sound_distro_df.sort_values(['total_sound_count'], ascending=False)\n",
    "\n",
    "#Creating the sound counts/file\n",
    "count_files = sound_distro_df.groupby(['sound','spec_sound_count']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing the distribution of sounds per file\\\n",
    "bins = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3)\n",
    "plt.figure(figsize=(5, 2))\n",
    "axs[0,0].bar(x=count_files.loc[count_files['sound']=='airplane']['spec_sound_count'],\n",
    "            height = count_files.loc[count_files['sound']=='airplane']['Metadata_files'])\n",
    "axs[0,1].bar(x=count_files.loc[count_files['sound']=='fish']['spec_sound_count'],\n",
    "            height = count_files.loc[count_files['sound']=='fish']['Metadata_files'])\n",
    "axs[0,2].bar(x=count_files.loc[count_files['sound']=='flow noise']['spec_sound_count'],\n",
    "            height = count_files.loc[count_files['sound']=='flow noise']['Metadata_files'])\n",
    "axs[1,0].bar(x=count_files.loc[count_files['sound']=='helicopter']['spec_sound_count'],\n",
    "            height = count_files.loc[count_files['sound']=='helicopter']['Metadata_files'])\n",
    "axs[1,1].bar(x=count_files.loc[count_files['sound']=='humpback']['spec_sound_count'],\n",
    "            height = count_files.loc[count_files['sound']=='humpback']['Metadata_files'])\n",
    "axs[1,2].bar(x=count_files.loc[count_files['sound']=='mooring']['spec_sound_count'],\n",
    "            height = count_files.loc[count_files['sound']=='mooring']['Metadata_files'])\n",
    "fig.tight_layout(pad = 2.0)\n",
    "axs[0,0].set_title('Airplane Sounds/File Distro', size = 8)\n",
    "axs[0,1].set_title('Fish Sounds/File Distro', size = 8)\n",
    "axs[0,2].set_title('Flow noise Sounds/File Distro', size = 8)\n",
    "axs[1,0].set_title('Helicopter Sounds/File Distro', size = 8)\n",
    "axs[1,1].set_title('Humpback Sounds/File Distro', size = 8)\n",
    "axs[1,2].set_title('Mooring Sounds/File Distro', size = 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f7e97f",
   "metadata": {},
   "source": [
    "We can see that few sounds occurr more than 10x per file. Airplanes, Fish, Helicopters and Mooring sounds tend to occur only once per file. VGGish will split sound files into 1 second increments, which amounts to ~30 splits per file. Depending on the duration of the sound this could lead to lots of \"dead\" time. To give us a good balance and range of sounds, minimize dead time, and maximize the \"efficiency\" of sounds/wav file we will select a file with ~10 humpback sounds, a file with ~10 mooring sounds, a file with ~10 flow noise sounds, and 2 files with ~5 fish sounds. This equates to 5 files. Ideally we can get a file which has the parameters of the previous sentence PLUS an airplane and/or helicopter noise.\n",
    "\n",
    "We will start by finding files which have 8-12 whales and/or an airplane and/or a helicopter. Ideally we would use  '20190222T190004-File-28Metadata' to get the WAV with 8 whales and 2 planes, but the metadata file doesn't appear in the MLFigsMeta file. Intsead we will use 20181227T100004-File-6Metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82386b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a giant file with all combos of sounds\n",
    "wav_select_df = pd.merge(left=sound_distro_df, right=sound_distro_df, how='cross')\n",
    "#wav_select_df.head()\n",
    "\n",
    "#Getting list of files with ~10 humpback sounds and/or and airplane sound\n",
    "wav_select_df.loc[(wav_select_df['Metadata_files_x']==wav_select_df['Metadata_files_y'])\n",
    "                 & (wav_select_df['sound_x']=='humpback')\n",
    "                 & (wav_select_df['spec_sound_count_x'] >=9)\n",
    "                 & (wav_select_df['spec_sound_count_x'] <= 11)\n",
    "                 & ((wav_select_df['sound_y']=='airplane') | (wav_select_df['sound_y']=='helicopter'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124481c6",
   "metadata": {},
   "source": [
    "Now we pull mooring files. There are no mooring files which contain helicopters or airplanes, so we will take '20181204T203004-File-0Metadata' with 9 identified mooring sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ad577",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Getting list of files with ~10 mooring sounds and/or and airplane sound\n",
    "wav_select_df.loc[(wav_select_df['Metadata_files_x']==wav_select_df['Metadata_files_y'])\n",
    "                 & (wav_select_df['sound_x']=='mooring')\n",
    "                 & (wav_select_df['spec_sound_count_x'] >=8)\n",
    "                 & (wav_select_df['spec_sound_count_x'] <=12)\n",
    "                 & ((wav_select_df['sound_y']=='airplane') | (wav_select_df['sound_y']=='helicopter'))]'''\n",
    "\n",
    "#Getting list of files with ~10 mooring sounds and/or and airplane sound\n",
    "wav_select_df.loc[(wav_select_df['Metadata_files_x']==wav_select_df['Metadata_files_y'])\n",
    "                 & (wav_select_df['sound_x']=='mooring')\n",
    "                 & (wav_select_df['spec_sound_count_x'] >=8)\n",
    "                 & (wav_select_df['spec_sound_count_x'] <=12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84129b7",
   "metadata": {},
   "source": [
    "Next we will get our list of flow noise files with airplanes/helicopters. Ideally we would have used  '20190221T100004-File-13Metadata' because it has both flow noise and a helicopter. However, this metadata file wasn't available. Instead we used 20181209T083004-File-21Metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Getting list of files with ~10 fish sounds and/or and airplane sound\n",
    "wav_select_df.loc[(wav_select_df['Metadata_files_x']==wav_select_df['Metadata_files_y'])\n",
    "                 & (wav_select_df['sound_x']=='flow noise')\n",
    "                 & (wav_select_df['spec_sound_count_x'] >=8)\n",
    "                 & (wav_select_df['spec_sound_count_x'] <=12)\n",
    "                 & ((wav_select_df['sound_y']=='airplane') | (wav_select_df['sound_y']=='helicopter'))]'''\n",
    "\n",
    "#Getting list of files with ~10 fish sounds and/or and airplane sound\n",
    "wav_select_df.loc[(wav_select_df['Metadata_files_x']==wav_select_df['Metadata_files_y'])\n",
    "                 & (wav_select_df['sound_x']=='flow noise')\n",
    "                 & (wav_select_df['spec_sound_count_x'] >=8)\n",
    "                 & (wav_select_df['spec_sound_count_x'] <=12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1676fe9",
   "metadata": {},
   "source": [
    "Now we need to get 2 fish files with ~5 recordings each, and ideally some airplanes and/or helicopters. Unfortunately there are none so We will select '20181227T053004-File-10Metadata' and '20181227T100004-File-20Metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a86c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting list of files with ~10 fish sounds and/or and airplane sound\n",
    "wav_select_df.loc[(wav_select_df['Metadata_files_x']==wav_select_df['Metadata_files_y'])\n",
    "                 & (wav_select_df['sound_x']=='fish')\n",
    "                 & (wav_select_df['spec_sound_count_x'] >=4)\n",
    "                 & ((wav_select_df['sound_y']=='airplane') | (wav_select_df['sound_y']=='helicopter'))]\n",
    "\n",
    "#Getting list of files with ~10 fish sounds and/or and airplane sound\n",
    "wav_select_df.loc[(wav_select_df['Metadata_files_x']==wav_select_df['Metadata_files_y'])\n",
    "                 & (wav_select_df['sound_x']=='fish')\n",
    "                 & (wav_select_df['spec_sound_count_x'] >=4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17227945",
   "metadata": {},
   "source": [
    "Now we create our final list of metadata files we need to bring over from the external hard drive to find the associated WAV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def57ddb",
   "metadata": {
    "scrolled": true,
    "tags": [
     "Metadata_files"
    ]
   },
   "outputs": [],
   "source": [
    "metadata_file_list = ['20181227T053004-File-10Metadata','20181227T100004-File-20Metadata',\n",
    "                      '20181209T083004-File-21Metadata',  '20181204T203004-File-0Metadata',\n",
    "                      '20181227T100004-File-6Metadata']\n",
    "print(\"The Metadata files which contain annotated spectrograms from the October 26th annotation batch and will be used in our POC are:\")\n",
    "print(metadata_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7784f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('20190221T100004-File-13.png has no metadata file')\n",
    "print('     Used 20181209T083004-File-21Metadata for flow noise instead')\n",
    "print('20190222T190004-File-28.png has no metadata file')\n",
    "print('     Used 20181227T100004-File-6Metadata for whales instead')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
