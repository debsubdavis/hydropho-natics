{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404a30d1",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "The purpose of this code is to map all .wav files to their spectrograms\n",
    "and most recent annotations. \n",
    "\n",
    "This code will allow the team to join datapoints output from VGGish\n",
    "to the original spectrogram annotations from Chris and team. This will\n",
    "allow the VGGish team to ground their clusters in known annotations.\n",
    "\n",
    "Input(s):\n",
    "1. Path to unique_images_annotations.csv file. This file contains the\n",
    "    image_file_name, image_file_path, and json_file_path for all the\n",
    "    annotated Fred Olsen images from Dec 2018 to Feb 2019.\n",
    "\n",
    "Output(s):\n",
    "1. CSV file with each wav file name, metadata file name, image file name,\n",
    "    json file name, annotation names (e.g., mooring, whale, airplane), and\n",
    "    the annotation coordinates\n",
    "\n",
    "Usage:\n",
    "1. This code will generate a csv which will be joined to the output datapoints\n",
    "    from the VGGish model.\n",
    "\n",
    "We'll start by importing some Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3eda72cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e4347",
   "metadata": {},
   "source": [
    "Now we will pull the information from the annotated JSON files stored on the external hard drive so we can get data labels, sound coordinates, and image file names. This is tricky because the same image may have been annotated multiple times. To ensure that we have pulled the most recent annotated file we will leverage the \"unique_images_annotations.csv\" generated by the \"unique_images_annotations.ipynb\". If the csv file doesn't exist, please stop now and run it to generate the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a20977d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sound                                             points  \\\n",
      "0     mooring  [[382.56626506024094, 614.4819277108433], [458...   \n",
      "1  helicopter  [[1920.952380952381, 1048.1904761904761], [216...   \n",
      "2     mooring  [[424.7349397590361, 748.2168674698794], [490....   \n",
      "3     mooring  [[1209.0722891566263, 938.5783132530119], [127...   \n",
      "4     mooring  [[1645.2168674698794, 744.6024096385541], [173...   \n",
      "\n",
      "                    image_name  \\\n",
      "0   20181204T100004-File-8.png   \n",
      "1   20181204T100004-File-8.png   \n",
      "2  20181204T113004-File-16.png   \n",
      "3  20181204T113004-File-16.png   \n",
      "4  20181204T113004-File-16.png   \n",
      "\n",
      "                                      json_file_path  \n",
      "0  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...  \n",
      "1  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...  \n",
      "2  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...  \n",
      "3  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...  \n",
      "4  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...  \n"
     ]
    }
   ],
   "source": [
    "#Creating a df to save the data in\n",
    "annotation_df = pd.DataFrame(columns=['sound','points','image_name', 'json_file_path'])\n",
    "annotation_df.head()\n",
    "\n",
    "#Getting the path to the JSON files & listing files\n",
    "uniq_annotation_df = pd.read_csv('unique_images_annotations.csv')\n",
    "json_file_list = list(uniq_annotation_df['json_file_path'])\n",
    "\n",
    "#Iterate through json files to get annotated image info\n",
    "for file in json_file_list:\n",
    "    #Loading the JSON data & turning into dict\n",
    "    annotated_file = open(file)\n",
    "    annotated_dict = json.load(annotated_file)\n",
    "    #annotated_dict.keys()\n",
    "\n",
    "    #Pulling out the labels, points, and image path\n",
    "    image_name = annotated_dict['imagePath']\n",
    "    if len(annotated_dict['shapes']) > 0:\n",
    "        for shape in annotated_dict['shapes']:\n",
    "            sound = shape['label']\n",
    "            points = shape['points']\n",
    "            annotation_df.loc[len(annotation_df.index)] = [sound, points, image_name, file]\n",
    "    else:\n",
    "        sound = None\n",
    "        points = None\n",
    "        annotation_df.loc[len(annotation_df.index)] = [sound, points, image_name, file]\n",
    "    \n",
    "#Validating that images paired with json from unique annotations file are the same as the images referenced in the JSON files themselves\n",
    "comb_df = pd.merge(left = uniq_annotation_df, right = annotation_df, how = 'left', left_on='json_file_path', right_on='json_file_path')\n",
    "comb_df['image_file_name_tester'] = comb_df['image_file_name']+'.png'\n",
    "comb_df['name_compare'] = np.where((comb_df['image_file_name_tester'] == comb_df['image_name']), 0, 1)\n",
    "if comb_df['name_compare'].sum() != 0:\n",
    "    print(\"The following json files contain different image filenames than those they were aligned to in the unique_image_annotations code\")\n",
    "    print(comb_df.loc[comb_df['name_compare']!=0])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#Validating we got all the json files from the original unique annotations dataframe in the new annotation df\n",
    "if len(uniq_annotation_df) != len(annotation_df['json_file_path'].unique()):\n",
    "    print(\"ERROR - not all JSON contained in the annotation_df\")\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#Examining head of file\n",
    "print(annotation_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076ec28",
   "metadata": {},
   "source": [
    "Now we need to match the annotated spectrograms with the wav files that generated them. We have the \"image_name\" info, everything before the \".png\" (call it X) will reference a file called XMetadata. Inside that XMetadata file there is a \"FileName\" which contains the raw title information which matches to the hydrophone recording title. As an example:\n",
    "\n",
    "    image_name: 20181204T100004-File-0.png\n",
    "    X: 20181204T100004-File-0\n",
    "    Metadata file: 20181204T100004-File-0Metadata\n",
    "    FileName: 181204-100002-437599-806141979_Spectrograms_20Hz.mat\n",
    "    Hydrophone recording name: 181204-100002-437599-806141979.wav\n",
    "\n",
    "By stripping off the \"_Spectrograms_20Hz.mat\" from the FileName we can get the prefix for the hydrophone recording name. We start by pulling each Metadata file, retrieving the contained FileName field, and getting the title prior to \"_Spectrogram...\". We add the Metadata file names to the annotated_info_df for easy reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1851210a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound</th>\n",
       "      <th>points</th>\n",
       "      <th>image_name</th>\n",
       "      <th>json_file_path</th>\n",
       "      <th>metadata_file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[382.56626506024094, 614.4819277108433], [458...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>helicopter</td>\n",
       "      <td>[[1920.952380952381, 1048.1904761904761], [216...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[424.7349397590361, 748.2168674698794], [490....</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1209.0722891566263, 938.5783132530119], [127...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1645.2168674698794, 744.6024096385541], [173...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sound                                             points  \\\n",
       "0     mooring  [[382.56626506024094, 614.4819277108433], [458...   \n",
       "1  helicopter  [[1920.952380952381, 1048.1904761904761], [216...   \n",
       "2     mooring  [[424.7349397590361, 748.2168674698794], [490....   \n",
       "3     mooring  [[1209.0722891566263, 938.5783132530119], [127...   \n",
       "4     mooring  [[1645.2168674698794, 744.6024096385541], [173...   \n",
       "\n",
       "                    image_name  \\\n",
       "0   20181204T100004-File-8.png   \n",
       "1   20181204T100004-File-8.png   \n",
       "2  20181204T113004-File-16.png   \n",
       "3  20181204T113004-File-16.png   \n",
       "4  20181204T113004-File-16.png   \n",
       "\n",
       "                                      json_file_path  \\\n",
       "0  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "1  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "2  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "3  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "4  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "\n",
       "                                  metadata_file_path  \n",
       "0  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...  \n",
       "1  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...  \n",
       "2  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...  \n",
       "3  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...  \n",
       "4  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the image prefixes\n",
    "image_names = list(annotation_df['image_name'])\n",
    "image_start = [name.replace('.png', '') for name in image_names]\n",
    "\n",
    "#Creating all the metadata file names\n",
    "metadata_names = []\n",
    "for image_name in image_start:\n",
    "    metadata_names.append('D:/1Dec2018_28Feb2019/MLFigsMeta/'+image_name+'Metadata.txt')\n",
    "    \n",
    "#Adding the metadata names to the table with annotation info\n",
    "annotation_df['metadata_file_path'] = metadata_names\n",
    "annotation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6001650b",
   "metadata": {},
   "source": [
    "Now we need to open each of those metadata files to extract the FileName, cut off the \"_Spectrogram...\" and append '.wav' to get the hydrophone recording name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c670e089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 images don't have an associated metadata file.\n",
      "This is 45.72% of all images\n",
      "SOLVE WITH CHRIS DURING MODEL ITERATION\n"
     ]
    }
   ],
   "source": [
    "#List of metadata file names\n",
    "metadata_file_names = annotation_df['metadata_file_path'].unique()\n",
    "\n",
    "#Creating a metadata df to store info taken from each file\n",
    "metadata_df = pd.DataFrame(columns=['metadata_file_path','filename','wav_filename', 'windows_plotted','starttime'])\n",
    "\n",
    "for file in metadata_file_names:\n",
    "    #Read all the lines in the filepath & save in array if it exists\n",
    "    #Otherwise add it to a list for printing later\n",
    "    try:\n",
    "        meta_file = open(file, 'r')\n",
    "        text = meta_file.readlines()\n",
    "        filename = text[1][10:-2]\n",
    "        starttime = text[2][11:-2]\n",
    "        windows_plotted = text[3][16:-2]\n",
    "        wav_filename = 'D:/1Dec2018_28Feb2019/Hydrophone/'+filename[:-24]+'.wav'\n",
    "        metadata_df.loc[len(metadata_df.index)] = [file, filename, wav_filename, windows_plotted, starttime]\n",
    "    except FileNotFoundError:\n",
    "        metadata_df.loc[len(metadata_df.index)] = [file, None, None, None, None]\n",
    "\n",
    "#Matching the metadata_df information back to annotation_df\n",
    "meta_annotation_df = pd.merge(left = annotation_df, right = metadata_df, how = 'left', on='metadata_file_path')\n",
    "#meta_annotation_df.head()\n",
    "\n",
    "#Seeing how many images don't have associated metadata files\n",
    "missing_metadata = meta_annotation_df[meta_annotation_df['filename'].isna()].groupby('image_name').count().sort_values('sound', ascending=False).reset_index()\n",
    "print(\"{0} images don't have an associated metadata file.\".format(len(missing_metadata)))\n",
    "print(\"This is {0}% of all images\".format(round(len(missing_metadata)*100/len(meta_annotation_df['image_name'].unique()),2)))\n",
    "print(\"IDENTIFY ISSUE AND SOLVE WITH CHRIS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3ac6e",
   "metadata": {},
   "source": [
    "Let's address the issue of the missing metadata files. In an earlier conversation with Chris he mentioned there being an error on the digit representing time in the filename. In the following image name we have 20181204T100004 which stands for 2018, December, 4th, time 10:00:04am. Let's see what happens if we try to match the missing files to metadata files using only the date and first 4 digits of time + the file number (e.g., File-0 in the below example).\n",
    "\n",
    "    image_name: 20181204T100004-File-0.png\n",
    "    X: 20181204T100004-File-0\n",
    "    Metadata file: 20181204T100004-File-0Metadata\n",
    "    FileName: 181204-100002-437599-806141979_Spectrograms_20Hz.mat\n",
    "    Hydrophone recording name: 181204-100002-437599-806141979.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e20d3c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files match based on the file number and YYYYMMDDTHHMM\n"
     ]
    }
   ],
   "source": [
    "#Checking the last time digit - all the images with missing metadata files end with \"04\" in the time\n",
    "missing_metadata['image_name'].str[13:16].unique()\n",
    "\n",
    "#Repeating the steps from above to flexibly match the metadata files based on the date and time out to 4 digits + the file number\n",
    "'''\n",
    "match the two dataframes on first n digits and file number\n",
    "check that each image has a unique metadata file\n",
    "is there something common about the image seconds and metadata seconds\n",
    "Create list to send to chris'''\n",
    "\n",
    "#Creating the empty unmatched image and metadata files \n",
    "unmatched_image_df = pd.DataFrame(columns=['image_name','firstn','seconds','file_number'])\n",
    "metadata_df = pd.DataFrame(columns=['metadata_name','firstn','seconds','file_number'])\n",
    "unmatched_images = list(missing_metadata['image_name'].unique())\n",
    "#print(unmatched_images)\n",
    "\n",
    "#Populating the unmatched_image_df\n",
    "for unmatched_image in unmatched_images:\n",
    "    unmatched_image_df.loc[len(unmatched_image_df.index)] = [unmatched_image, unmatched_image[:13], unmatched_image[13:15],\n",
    "                                                             unmatched_image[16:-4]]\n",
    "#Populating the unmatched metadata_df\n",
    "hd_path = 'D:/1Dec2018_28Feb2019/MLFigsMeta'\n",
    "all_metadata_files = [file for file in listdir(hd_path) if isfile(join(hd_path, file))]\n",
    "for file in all_metadata_files:\n",
    "    metadata_df.loc[len(metadata_df.index)] = [file, file[:13], file[13:15], file[16:-12]]\n",
    "\n",
    "#Match the unmatched files on firstn and file_number\n",
    "fuzzy_match_df = pd.merge(left = unmatched_image_df, right = metadata_df, how = 'inner',\n",
    "                          on=['firstn', 'file_number'])\n",
    "if len(fuzzy_match_df) == 0:\n",
    "    print(\"No files match based on the file number and YYYYMMDDTHHMM\")\n",
    "else:\n",
    "    print(\"YAY we found some files - dig into df to discover which files match\")\n",
    "#NO FILES MATCH BASED ON THE FILE NUMBER AND THE YYYYMMDDTHHMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f8ec90",
   "metadata": {},
   "source": [
    "Unfortunately it appears that there are no metadata files which match with the previously unmatched images when we attempt to keep the year, month, day, hours, and minutes the same. Perhaps the issue is with the minutes and the seconds, leading to the lack of matches. We will try the same matching procedure as the above, but matching on only the YYYYMMDDTHH in the image and metadata filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "97006430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately there are still no matches based on YYYYMMDDTHH and file number elements.\n"
     ]
    }
   ],
   "source": [
    "#TRYING SAME LOGIC MATCHING ON YYYY, MM, DD, AND HH ONLY\n",
    "\n",
    "#Creating the empty unmatched image and metadata files \n",
    "unmatched_image_11 = pd.DataFrame(columns=['image_name','firstn','min_sec','file_number'])\n",
    "unmatched_metadata_11 = pd.DataFrame(columns=['metadata_name','firstn','min_sec','file_number'])\n",
    "unmatched_images_11 = list(missing_metadata['image_name'].unique())\n",
    "#print(unmatched_images)\n",
    "\n",
    "#Populating the unmatched_image_11\n",
    "for unmatched_image in unmatched_images_11:\n",
    "    unmatched_image_11.loc[len(unmatched_image_11.index)] = [unmatched_image, unmatched_image[:11], unmatched_image[11:15],\n",
    "                                                             unmatched_image[16:-4]]\n",
    "\n",
    "#Populating unmatched_metadata_11\n",
    "for file in all_metadata_files:\n",
    "    unmatched_metadata_11.loc[len(unmatched_metadata_11.index)] = [\n",
    "        file, file[:11], file[11:15], file[16:-12]\n",
    "    ]\n",
    "\n",
    "#Trying to match on YYYY, MM, DD, T, HH\n",
    "matching_11 = pd.merge(left = unmatched_image_11, right = unmatched_metadata_11, how='inner',\n",
    "                       on=['firstn', 'file_number'])\n",
    "\n",
    "#Testing for matches\n",
    "if len(matching_11) == 0:\n",
    "    print(\"Unfortunately there are still no matches based on YYYYMMDDTHH and file number elements.\")\n",
    "else:\n",
    "    print(\"YAY! Some files matched. Check df for more information.\")\n",
    "#THERE ARE NO METADATA FILES THAT MATCH THE UNMATCHED IMAGES ON THE SAME DAY & FILE NUMBER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b477464",
   "metadata": {},
   "source": [
    "We are still failing to find any matches between the unmatched images and metadata files. Perhaps the image files were taken from a time not covered by the metadata. Comparing the start and end dates of metadta to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d51f58c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 days which have images with no accompanying metadata.\n",
      "There are 42 days with at least one metadata file.\n",
      "There are 0 days which overlap between metadata file coverage and unmatched images.\n",
      "The unmatched image file dates range from 20190115 to 20190223.\n",
      "The metadata file dates range from 20181204 to 20190114.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sorting the df for easier comparison\n",
    "unmatched_image_df = unmatched_image_df.sort_values('firstn', axis= 0, ascending=True)\n",
    "sorted_metadata_df = metadata_df.sort_values('firstn',axis=0, ascending=True)\n",
    "\n",
    "#looking at dates for unmatched images\n",
    "unmatched_image_df['date'] = unmatched_image_df['firstn'].str[:-5]\n",
    "unmatched_image_date_set= set(unmatched_image_df['date'])\n",
    "print(\"There are {0} days which have images with no accompanying metadata.\".format(len(unmatched_image_date_set)))\n",
    "\n",
    "#looking at dates for metadata files\n",
    "sorted_metadata_df['date'] = sorted_metadata_df['firstn'].str[:-5]\n",
    "metadata_date_set = set(sorted_metadata_df['date'])\n",
    "print(\"There are {0} days with at least one metadata file.\".format(len(metadata_date_set)))\n",
    "\n",
    "#Checking the overlap of days\n",
    "both_dates = metadata_date_set.intersection(unmatched_image_date_set)\n",
    "print(\"There are {0} days which overlap between metadata file coverage and unmatched images.\".format(len(both_dates)))\n",
    "\n",
    "\n",
    "#Understanding the range of days\n",
    "print(\"The unmatched image file dates range from {0} to {1}.\".format(min(unmatched_image_date_set), max(unmatched_image_date_set)))\n",
    "print(\"The metadata file dates range from {0} to {1}.\".format(min(metadata_date_set), max(metadata_date_set)))\n",
    "#print(sorted(metadata_date_set))\n",
    "#print(sorted(unmatched_image_date_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c2e786",
   "metadata": {},
   "source": [
    "It would be nice to ask Chris for the missing metadata files so we can tie them back to the wav files processed by VGGish. To quantify what we are missing, how many annotations do we have vs. not have in each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "03ed5a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of annotated sounds by matched metadata status is as follows:\n",
      "matched_metadata  sound        \n",
      "0                 airplane           18\n",
      "                  boat                8\n",
      "                  fish               21\n",
      "                  flow noise        471\n",
      "                  helicopter          8\n",
      "                  humpback         1130\n",
      "                  mooring            56\n",
      "1                 airplane           14\n",
      "                  fish               67\n",
      "                  flow noise        345\n",
      "                  helicopter         15\n",
      "                  humpback          391\n",
      "                  mooring           405\n",
      "                  mooring noise       3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Define function with matching\n",
    "def label_matches(row):\n",
    "    if row['filename'] == None:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "#Apply that function to the df\n",
    "meta_annotation_df['matched_metadata'] = meta_annotation_df.apply(label_matches, axis = 1)\n",
    "meta_annotation_df\n",
    "\n",
    "#Grouping annotations by metadata matched vs. not matched\n",
    "print(\"The distribution of annotated sounds by matched metadata status is as follows:\")\n",
    "print(meta_annotation_df.groupby(['matched_metadata','sound']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ec1a9352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of unique images by matched metadata status is as follows:\n",
      "matched_metadata\n",
      "0    187\n",
      "1    222\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#meta_annotation_df['image_name'].groupby(['matched_metadata', 'image_name']).size()\n",
    "images_matching_status = meta_annotation_df[['image_name', 'matched_metadata']].drop_duplicates()\n",
    "\n",
    "print(\"The distribution of unique images by matched metadata status is as follows:\")\n",
    "print(images_matching_status.groupby('matched_metadata').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18af702",
   "metadata": {},
   "source": [
    "# AFTER CHRIS PROVIDES NEW METADATA, CHECK WAV FILE MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "689a0fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT - 1325 files in the hard drive, only 140 in the meta_annotation_df.\n"
     ]
    }
   ],
   "source": [
    "#Testing to see if all wav files have been accounted for in the meta_annotation_df\n",
    "\n",
    "#Getting list of wav files from hard drive\n",
    "wav_list = [file for file in os.listdir('D:/1Dec2018_28Feb2019/Hydrophone/') if file.endswith('.wav')]\n",
    "\n",
    "#List of wav files from meta_annotation_df\n",
    "matched_wav_list = list(meta_annotation_df['wav_filename'].unique())\n",
    "\n",
    "if len(wav_list) != len(matched_wav_list):\n",
    "    print(\"ALERT - {0} files in the hard drive, only {1} in the meta_annotation_df.\".format(len(wav_list), len(matched_wav_list)))\n",
    "else:\n",
    "    print(\"All wav files accounted for in meta_annotation_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e91a0",
   "metadata": {},
   "source": [
    "Now that we have wav files mapped back to their annotations, we need to understand what time each annotation occurs. We do this to ultimately map back to our VGGish embeddings which occurr every 0.96 seconds. We start by translating the \"windows_plotted\" back into audio seconds. From Chris' README we know that:\n",
    "\n",
    "- Windows plotted: Tells which files from the audio file are plotted. If 20 Hz spectrograms and the first \n",
    "           minute of the file this would be 1-1201. If the second minute they would be 1202-1401 etc. \n",
    "           These were saved because it would be possible to closely map the time of a second from the\n",
    "           window number and file start time.\n",
    "\n",
    "Based on that information we can surmise that 1 minute of audio = 1200 windows. We need to get the start and end number of windows, subtract them, and divide by 1200 to understand how much time is covered by each spectrogram. In the next block of code we will look at the annotation coordinates to find the more granular location in time from the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "17e6dbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound</th>\n",
       "      <th>points</th>\n",
       "      <th>image_name</th>\n",
       "      <th>json_file_path</th>\n",
       "      <th>metadata_file_path</th>\n",
       "      <th>filename</th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>windows_plotted</th>\n",
       "      <th>starttime</th>\n",
       "      <th>matched_metadata</th>\n",
       "      <th>time_in_spectrogram_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[382.56626506024094, 614.4819277108433], [458...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "      <td>181204-100002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...</td>\n",
       "      <td>9602-10801</td>\n",
       "      <td>20181204T100004</td>\n",
       "      <td>1</td>\n",
       "      <td>59.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>helicopter</td>\n",
       "      <td>[[1920.952380952381, 1048.1904761904761], [216...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "      <td>181204-100002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...</td>\n",
       "      <td>9602-10801</td>\n",
       "      <td>20181204T100004</td>\n",
       "      <td>1</td>\n",
       "      <td>59.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[424.7349397590361, 748.2168674698794], [490....</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>19202-20401</td>\n",
       "      <td>20181204T113004</td>\n",
       "      <td>1</td>\n",
       "      <td>59.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1209.0722891566263, 938.5783132530119], [127...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>19202-20401</td>\n",
       "      <td>20181204T113004</td>\n",
       "      <td>1</td>\n",
       "      <td>59.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1645.2168674698794, 744.6024096385541], [173...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>19202-20401</td>\n",
       "      <td>20181204T113004</td>\n",
       "      <td>1</td>\n",
       "      <td>59.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sound                                             points  \\\n",
       "0     mooring  [[382.56626506024094, 614.4819277108433], [458...   \n",
       "1  helicopter  [[1920.952380952381, 1048.1904761904761], [216...   \n",
       "2     mooring  [[424.7349397590361, 748.2168674698794], [490....   \n",
       "3     mooring  [[1209.0722891566263, 938.5783132530119], [127...   \n",
       "4     mooring  [[1645.2168674698794, 744.6024096385541], [173...   \n",
       "\n",
       "                    image_name  \\\n",
       "0   20181204T100004-File-8.png   \n",
       "1   20181204T100004-File-8.png   \n",
       "2  20181204T113004-File-16.png   \n",
       "3  20181204T113004-File-16.png   \n",
       "4  20181204T113004-File-16.png   \n",
       "\n",
       "                                      json_file_path  \\\n",
       "0  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "1  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "2  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "3  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "4  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "\n",
       "                                  metadata_file_path  \\\n",
       "0  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...   \n",
       "1  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...   \n",
       "2  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "3  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "4  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "\n",
       "                                            filename  \\\n",
       "0  181204-100002-437599-806141979_Spectrograms_20...   \n",
       "1  181204-100002-437599-806141979_Spectrograms_20...   \n",
       "2  181204-113002-437599-806141979_Spectrograms_20...   \n",
       "3  181204-113002-437599-806141979_Spectrograms_20...   \n",
       "4  181204-113002-437599-806141979_Spectrograms_20...   \n",
       "\n",
       "                                        wav_filename windows_plotted  \\\n",
       "0  D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...      9602-10801   \n",
       "1  D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...      9602-10801   \n",
       "2  D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...     19202-20401   \n",
       "3  D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...     19202-20401   \n",
       "4  D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...     19202-20401   \n",
       "\n",
       "         starttime  matched_metadata  time_in_spectrogram_secs  \n",
       "0  20181204T100004                 1                     59.95  \n",
       "1  20181204T100004                 1                     59.95  \n",
       "2  20181204T113004                 1                     59.95  \n",
       "3  20181204T113004                 1                     59.95  \n",
       "4  20181204T113004                 1                     59.95  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Breaking apart the windows_plotted into a start_window and stop_window\n",
    "meta_annotation_df['start_window'] = meta_annotation_df['windows_plotted'].str.split('-').str[0]\n",
    "meta_annotation_df['stop_window'] = meta_annotation_df['windows_plotted'].str.split('-').str[1]\n",
    "\n",
    "#Subtracting the two windows to get the total time represented by the spectrogram\n",
    "meta_annotation_df['time_in_spectrogram_window'] = pd.to_numeric(meta_annotation_df['stop_window']) - pd.to_numeric(meta_annotation_df['start_window'])\n",
    "\n",
    "#Time represented by spectrogram in minutes\n",
    "meta_annotation_df['time_in_spectrogram_secs'] = (meta_annotation_df['time_in_spectrogram_window']/1200)*60\n",
    "\n",
    "#Dropping the extra calculation columns\n",
    "meta_annotation_df = meta_annotation_df.drop(['start_window','stop_window', 'time_in_spectrogram_window'], axis = 1)\n",
    "meta_annotation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fbd806",
   "metadata": {},
   "source": [
    "# VERIFY THE BELOW 2/6\n",
    "\n",
    "In the next block of code we will create a column detailing the start and end time the annotated noise occurred. When added to the \"time_in_spectrogram_secs\" measurement, it will tell us when in the audio file the annotation approximately occurred. Per Debbie, we know that the \"points\" are in pixels, and there are X pixels across the horizontal (time) axis. Knowing each file is ~1 minute in length, each pixel is X seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86310ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f241133",
   "metadata": {},
   "source": [
    "Now that we know when each annotation occurred in the wav file, we can match back to the ~1800 slices created by VGGish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8c54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1f07721",
   "metadata": {},
   "source": [
    "Finally, we save the final output as wav_to_annotations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ac0724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving wav to annotation information for future use\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound</th>\n",
       "      <th>points</th>\n",
       "      <th>image_name</th>\n",
       "      <th>json_file_path</th>\n",
       "      <th>metadata_file_path</th>\n",
       "      <th>filename</th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>windows_plotted</th>\n",
       "      <th>starttime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[382.56626506024094, 614.4819277108433], [458...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "      <td>181204-100002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...</td>\n",
       "      <td>9602-10801</td>\n",
       "      <td>20181204T100004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>helicopter</td>\n",
       "      <td>[[1920.952380952381, 1048.1904761904761], [216...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "      <td>181204-100002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...</td>\n",
       "      <td>9602-10801</td>\n",
       "      <td>20181204T100004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[424.7349397590361, 748.2168674698794], [490....</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>19202-20401</td>\n",
       "      <td>20181204T113004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1209.0722891566263, 938.5783132530119], [127...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>19202-20401</td>\n",
       "      <td>20181204T113004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1645.2168674698794, 744.6024096385541], [173...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>19202-20401</td>\n",
       "      <td>20181204T113004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sound                                             points  \\\n",
       "0     mooring  [[382.56626506024094, 614.4819277108433], [458...   \n",
       "1  helicopter  [[1920.952380952381, 1048.1904761904761], [216...   \n",
       "2     mooring  [[424.7349397590361, 748.2168674698794], [490....   \n",
       "3     mooring  [[1209.0722891566263, 938.5783132530119], [127...   \n",
       "4     mooring  [[1645.2168674698794, 744.6024096385541], [173...   \n",
       "\n",
       "                    image_name  \\\n",
       "0   20181204T100004-File-8.png   \n",
       "1   20181204T100004-File-8.png   \n",
       "2  20181204T113004-File-16.png   \n",
       "3  20181204T113004-File-16.png   \n",
       "4  20181204T113004-File-16.png   \n",
       "\n",
       "                                      json_file_path  \\\n",
       "0  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "1  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "2  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "3  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "4  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "\n",
       "                                  metadata_file_path  \\\n",
       "0  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...   \n",
       "1  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...   \n",
       "2  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "3  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "4  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "\n",
       "                                            filename  \\\n",
       "0  181204-100002-437599-806141979_Spectrograms_20...   \n",
       "1  181204-100002-437599-806141979_Spectrograms_20...   \n",
       "2  181204-113002-437599-806141979_Spectrograms_20...   \n",
       "3  181204-113002-437599-806141979_Spectrograms_20...   \n",
       "4  181204-113002-437599-806141979_Spectrograms_20...   \n",
       "\n",
       "                                        wav_filename windows_plotted  \\\n",
       "0  D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...      9602-10801   \n",
       "1  D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...      9602-10801   \n",
       "2  D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...     19202-20401   \n",
       "3  D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...     19202-20401   \n",
       "4  D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...     19202-20401   \n",
       "\n",
       "         starttime  \n",
       "0  20181204T100004  \n",
       "1  20181204T100004  \n",
       "2  20181204T113004  \n",
       "3  20181204T113004  \n",
       "4  20181204T113004  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the file\n",
    "print('Saving wav to annotation information for future use')\n",
    "meta_annotation_df.to_csv('wav_to_annotation.csv')\n",
    "meta_annotation_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
