{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404a30d1",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "The purpose of this code is to map all .wav files to their spectrograms\n",
    "and most recent annotations. \n",
    "\n",
    "This code will allow the team to join datapoints output from VGGish\n",
    "to the original spectrogram annotations from Chris and team. This will\n",
    "allow the VGGish team to ground their clusters in known annotations.\n",
    "\n",
    "Input(s):\n",
    "1. Path to unique_images_annotations.csv file. This file contains the\n",
    "    image_file_name, image_file_path, and json_file_path for all the\n",
    "    annotated Fred Olsen images from Dec 2018 to Feb 2019.\n",
    "\n",
    "Output(s):\n",
    "1. CSV file with each wav file name, metadata file name, image file name,\n",
    "    json file name, annotation names (e.g., mooring, whale, airplane), and\n",
    "    the annotation coordinates\n",
    "\n",
    "Usage:\n",
    "1. This code will generate a csv which will be joined to the output datapoints\n",
    "    from the VGGish model.\n",
    "\n",
    "We'll start by importing some Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3eda72cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e4347",
   "metadata": {},
   "source": [
    "Now we will pull the information from the annotated JSON files stored on the external hard drive so we can get data labels, sound coordinates, and image file names. This is tricky because the same image may have been annotated multiple times. To ensure that we have pulled the most recent annotated file we will leverage the \"unique_images_annotations.csv\" generated by the \"unique_images_annotations.ipynb\". If the csv file doesn't exist, please stop now and run it to generate the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9a20977d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sound                                             points  \\\n",
      "0     mooring  [[382.56626506024094, 614.4819277108433], [458...   \n",
      "1  helicopter  [[1920.952380952381, 1048.1904761904761], [216...   \n",
      "2     mooring  [[424.7349397590361, 748.2168674698794], [490....   \n",
      "3     mooring  [[1209.0722891566263, 938.5783132530119], [127...   \n",
      "4     mooring  [[1645.2168674698794, 744.6024096385541], [173...   \n",
      "\n",
      "                    image_name  \\\n",
      "0   20181204T100004-File-8.png   \n",
      "1   20181204T100004-File-8.png   \n",
      "2  20181204T113004-File-16.png   \n",
      "3  20181204T113004-File-16.png   \n",
      "4  20181204T113004-File-16.png   \n",
      "\n",
      "                                      json_file_path  \n",
      "0  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...  \n",
      "1  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...  \n",
      "2  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...  \n",
      "3  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...  \n",
      "4  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...  \n"
     ]
    }
   ],
   "source": [
    "#Creating a df to save the data in\n",
    "annotation_df = pd.DataFrame(columns=['sound','points','image_name', 'json_file_path'])\n",
    "annotation_df.head()\n",
    "\n",
    "#Getting the path to the JSON files & listing files\n",
    "uniq_annotation_df = pd.read_csv('unique_images_annotations.csv')\n",
    "json_file_list = list(uniq_annotation_df['json_file_path'])\n",
    "\n",
    "#Iterate through json files on external hard drive to get annotated image info\n",
    "for file in json_file_list:\n",
    "    #Loading the JSON data & turning into dict\n",
    "    annotated_file = open(file)\n",
    "    annotated_dict = json.load(annotated_file)\n",
    "    #annotated_dict.keys()\n",
    "\n",
    "    #Pulling out the labels, points, and image path\n",
    "    image_name = annotated_dict['imagePath']\n",
    "    if len(annotated_dict['shapes']) > 0:\n",
    "        for shape in annotated_dict['shapes']:\n",
    "            sound = shape['label']\n",
    "            points = shape['points']\n",
    "            annotation_df.loc[len(annotation_df.index)] = [sound, points, image_name, file]\n",
    "    else:\n",
    "        sound = None\n",
    "        points = None\n",
    "        annotation_df.loc[len(annotation_df.index)] = [sound, points, image_name, file]\n",
    "    \n",
    "#Validating that images paired with json from unique annotations file are the same as the images referenced in the JSON files themselves\n",
    "comb_df = pd.merge(left = uniq_annotation_df, right = annotation_df, how = 'left', left_on='json_file_path', right_on='json_file_path')\n",
    "comb_df['image_file_name_tester'] = comb_df['image_file_name']+'.png'\n",
    "comb_df['name_compare'] = np.where((comb_df['image_file_name_tester'] == comb_df['image_name']), 0, 1)\n",
    "if comb_df['name_compare'].sum() != 0:\n",
    "    print(\"The following json files contain different image filenames than those they were aligned to in the unique_image_annotations code\")\n",
    "    print(comb_df.loc[comb_df['name_compare']!=0])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#Validating we got all the json files from the original unique annotations dataframe in the new annotation df\n",
    "if len(uniq_annotation_df) != len(annotation_df['json_file_path'].unique()):\n",
    "    print(\"ERROR - not all JSON contained in the annotation_df\")\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#Examining head of file\n",
    "print(annotation_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076ec28",
   "metadata": {},
   "source": [
    "Now we need to match the annotated spectrograms with the wav files that generated them. We have the \"image_name\" info, everything before the \".png\" (call it X) will reference a file called XMetadata. Inside that XMetadata file there is a \"FileName\" which contains the raw title information which matches to the hydrophone recording title. As an example:\n",
    "\n",
    "    image_name: 20181204T100004-File-0.png\n",
    "    X: 20181204T100004-File-0\n",
    "    Metadata file: 20181204T100004-File-0Metadata\n",
    "    FileName: 181204-100002-437599-806141979_Spectrograms_20Hz.mat\n",
    "    Hydrophone recording name: 181204-100002-437599-806141979.wav\n",
    "\n",
    "By stripping off the \"_Spectrograms_20Hz.mat\" from the FileName we can get the prefix for the hydrophone recording name. We start by pulling each Metadata file, retrieving the contained FileName field, and getting the title prior to \"_Spectrogram...\". We add the Metadata file names to the annotated_info_df for easy reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1851210a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound</th>\n",
       "      <th>points</th>\n",
       "      <th>image_name</th>\n",
       "      <th>json_file_path</th>\n",
       "      <th>metadata_file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[382.56626506024094, 614.4819277108433], [458...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>helicopter</td>\n",
       "      <td>[[1920.952380952381, 1048.1904761904761], [216...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[424.7349397590361, 748.2168674698794], [490....</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1209.0722891566263, 938.5783132530119], [127...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1645.2168674698794, 744.6024096385541], [173...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sound                                             points  \\\n",
       "0     mooring  [[382.56626506024094, 614.4819277108433], [458...   \n",
       "1  helicopter  [[1920.952380952381, 1048.1904761904761], [216...   \n",
       "2     mooring  [[424.7349397590361, 748.2168674698794], [490....   \n",
       "3     mooring  [[1209.0722891566263, 938.5783132530119], [127...   \n",
       "4     mooring  [[1645.2168674698794, 744.6024096385541], [173...   \n",
       "\n",
       "                    image_name  \\\n",
       "0   20181204T100004-File-8.png   \n",
       "1   20181204T100004-File-8.png   \n",
       "2  20181204T113004-File-16.png   \n",
       "3  20181204T113004-File-16.png   \n",
       "4  20181204T113004-File-16.png   \n",
       "\n",
       "                                      json_file_path  \\\n",
       "0  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "1  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "2  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "3  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "4  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "\n",
       "                                  metadata_file_path  \n",
       "0  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...  \n",
       "1  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...  \n",
       "2  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...  \n",
       "3  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...  \n",
       "4  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the image prefixes\n",
    "image_names = list(annotation_df['image_name'])\n",
    "image_start = [name.replace('.png', '') for name in image_names]\n",
    "\n",
    "#Creating all the metadata file names\n",
    "metadata_names = []\n",
    "for image_name in image_start:\n",
    "    metadata_names.append('D:/1Dec2018_28Feb2019/MLFigsMeta/'+image_name+'Metadata.txt')\n",
    "    \n",
    "#Adding the metadata names to the table with annotation info\n",
    "annotation_df['metadata_file_path'] = metadata_names\n",
    "annotation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6001650b",
   "metadata": {},
   "source": [
    "Now we need to open each of those metadata files to extract the FileName, cut off the \"_Spectrogram...\" and append '.wav' to get the hydrophone recording name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c670e089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 images don't have an associated metadata file.\n",
      "This is 45.72% of all images\n",
      "IDENTIFY ISSUE AND SOLVE WITH CHRIS\n"
     ]
    }
   ],
   "source": [
    "#List of metadata file names\n",
    "metadata_file_names = annotation_df['metadata_file_path'].unique()\n",
    "\n",
    "#Creating a metadata df to store info taken from each file\n",
    "metadata_df = pd.DataFrame(columns=['metadata_file_path','filename','wav_filename', 'windows_plotted'])\n",
    "\n",
    "for file in metadata_file_names:\n",
    "    #Read all the lines in the filepath & save in array if it exists\n",
    "    #Otherwise add it to a list for printing later\n",
    "    try:\n",
    "        meta_file = open(file, 'r')\n",
    "        text = meta_file.readlines()\n",
    "        filename = text[1][10:-2]\n",
    "        #starttime = text[2][11:-2]\n",
    "        windows_plotted = text[3][16:-2]\n",
    "        wav_filename = 'D:/1Dec2018_28Feb2019/Hydrophone/'+filename[:-24]+'.wav'\n",
    "        metadata_df.loc[len(metadata_df.index)] = [file, filename, wav_filename, windows_plotted]\n",
    "    except FileNotFoundError:\n",
    "        metadata_df.loc[len(metadata_df.index)] = [file, None, None, None]\n",
    "\n",
    "#Matching the metadata_df information back to annotation_df\n",
    "meta_annotation_df = pd.merge(left = annotation_df, right = metadata_df, how = 'left', on='metadata_file_path')\n",
    "#meta_annotation_df.head()\n",
    "\n",
    "#Seeing how many images don't have associated metadata files\n",
    "missing_metadata = meta_annotation_df[meta_annotation_df['filename'].isna()].groupby('image_name').count().sort_values('sound', ascending=False).reset_index()\n",
    "print(\"{0} images don't have an associated metadata file.\".format(len(missing_metadata)))\n",
    "print(\"This is {0}% of all images\".format(round(len(missing_metadata)*100/len(meta_annotation_df['image_name'].unique()),2)))\n",
    "print(\"IDENTIFY ISSUE AND SOLVE WITH CHRIS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3ac6e",
   "metadata": {},
   "source": [
    "Let's address the issue of the missing metadata files. In an earlier conversation with Chris he mentioned there being an error on the digit representing time in the filename. In the following image name we have 20181204T100004 which stands for 2018, December, 4th, time 10:00:04am. Let's see what happens if we try to match the missing files to metadata files using only the date and first 4 digits of time + the file number (e.g., File-0 in the below example).\n",
    "\n",
    "    image_name: 20181204T100004-File-0.png\n",
    "    X: 20181204T100004-File-0\n",
    "    Metadata file: 20181204T100004-File-0Metadata\n",
    "    FileName: 181204-100002-437599-806141979_Spectrograms_20Hz.mat\n",
    "    Hydrophone recording name: 181204-100002-437599-806141979.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e20d3c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files match based on the file number and YYYYMMDDTHHMM\n"
     ]
    }
   ],
   "source": [
    "#Checking the last time digit - all the images with missing metadata files end with \"04\" in the time\n",
    "missing_metadata['image_name'].str[13:16].unique()\n",
    "\n",
    "#Repeating the steps from above to flexibly match the metadata files based on the date and time out to 4 digits + the file number\n",
    "#Creating the empty unmatched image and metadata files \n",
    "unmatched_image_df = pd.DataFrame(columns=['image_name','firstn','seconds','file_number'])\n",
    "metadata_df = pd.DataFrame(columns=['metadata_name','firstn','seconds','file_number'])\n",
    "unmatched_images = list(missing_metadata['image_name'].unique())\n",
    "#print(unmatched_images)\n",
    "\n",
    "#Populating the unmatched_image_df\n",
    "for unmatched_image in unmatched_images:\n",
    "    unmatched_image_df.loc[len(unmatched_image_df.index)] = [unmatched_image, unmatched_image[:13], unmatched_image[13:15],\n",
    "                                                             unmatched_image[16:-4]]\n",
    "#Populating the unmatched metadata_df\n",
    "hd_path = 'D:/1Dec2018_28Feb2019/MLFigsMeta'\n",
    "all_metadata_files = [file for file in listdir(hd_path) if isfile(join(hd_path, file))]\n",
    "for file in all_metadata_files:\n",
    "    metadata_df.loc[len(metadata_df.index)] = [file, file[:13], file[13:15], file[16:-12]]\n",
    "\n",
    "#Match the unmatched files on firstn and file_number\n",
    "fuzzy_match_df = pd.merge(left = unmatched_image_df, right = metadata_df, how = 'inner',\n",
    "                          on=['firstn', 'file_number'])\n",
    "if len(fuzzy_match_df) == 0:\n",
    "    print(\"No files match based on the file number and YYYYMMDDTHHMM\")\n",
    "else:\n",
    "    print(\"YAY we found some files - dig into df to discover which files match\")\n",
    "#NO FILES MATCH BASED ON THE FILE NUMBER AND THE YYYYMMDDTHHMM\n",
    "\n",
    "#Saving DF so we don't have to pull them every time\n",
    "unmatched_image_df.to_csv('unmatched_image_info.csv', index=False)\n",
    "metadata_df.to_csv('all_metadata_file_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f8ec90",
   "metadata": {},
   "source": [
    "Unfortunately it appears that there are no metadata files which match with the previously unmatched images when we attempt to keep the year, month, day, hours, and minutes the same. Perhaps the issue is with the minutes and the seconds, leading to the lack of matches. We will try the same matching procedure as the above, but matching on only the YYYYMMDDTHH in the image and metadata filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "97006430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately there are still no matches based on YYYYMMDDTHH and file number elements.\n"
     ]
    }
   ],
   "source": [
    "#TRYING SAME LOGIC MATCHING ON YYYY, MM, DD, AND HH ONLY\n",
    "#Opening the unmatched_image and all_metadata_file csvs created earlier so we don't have to remake them\n",
    "unmatched_image_df = pd.read_csv('unmatched_image_info.csv')\n",
    "metadata_df = pd.read_csv('all_metadata_file_info.csv')\n",
    "\n",
    "#Creating the empty unmatched image and metadata files \n",
    "unmatched_image_11 = pd.DataFrame(columns=['image_name','firstn','min_sec','file_number'])\n",
    "unmatched_metadata_11 = pd.DataFrame(columns=['metadata_name','firstn','min_sec','file_number'])\n",
    "unmatched_images_11 = list(missing_metadata['image_name'].unique())\n",
    "#print(unmatched_images)\n",
    "\n",
    "#Populating the unmatched_image_11\n",
    "for unmatched_image in unmatched_images_11:\n",
    "    unmatched_image_11.loc[len(unmatched_image_11.index)] = [unmatched_image, unmatched_image[:11], unmatched_image[11:15],\n",
    "                                                             unmatched_image[16:-4]]\n",
    "\n",
    "#Populating unmatched_metadata_11\n",
    "for file in all_metadata_files:\n",
    "    unmatched_metadata_11.loc[len(unmatched_metadata_11.index)] = [\n",
    "        file, file[:11], file[11:15], file[16:-12]\n",
    "    ]\n",
    "\n",
    "#Trying to match on YYYY, MM, DD, T, HH\n",
    "matching_11 = pd.merge(left = unmatched_image_11, right = unmatched_metadata_11, how='inner',\n",
    "                       on=['firstn', 'file_number'])\n",
    "\n",
    "#Testing for matches\n",
    "if len(matching_11) == 0:\n",
    "    print(\"Unfortunately there are still no matches based on YYYYMMDDTHH and file number elements.\")\n",
    "else:\n",
    "    print(\"YAY! Some files matched. Check df for more information.\")\n",
    "#THERE ARE NO METADATA FILES THAT MATCH THE UNMATCHED IMAGES ON THE SAME DAY & FILE NUMBER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b477464",
   "metadata": {},
   "source": [
    "We are still failing to find any matches between the unmatched images and metadata files. Perhaps the image files were taken from a time not covered by the metadata. Comparing the start and end dates of metadta to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d51f58c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 days which have images with no accompanying metadata.\n",
      "There are 42 days with at least one metadata file.\n",
      "There are 0 days which overlap between metadata file coverage and unmatched images.\n",
      "The unmatched image file dates range from 20190115 to 20190223.\n",
      "The metadata file dates range from 20181204 to 20190114.\n"
     ]
    }
   ],
   "source": [
    "#Opening the unmatched_image and all_metadata_file csvs created earlier so we don't have to remake them\n",
    "unmatched_image_df = pd.read_csv('unmatched_image_info.csv')\n",
    "metadata_df = pd.read_csv('all_metadata_file_info.csv')\n",
    "\n",
    "#Sorting the df for easier comparison\n",
    "unmatched_image_df = unmatched_image_df.sort_values('firstn', axis= 0, ascending=True)\n",
    "sorted_metadata_df = metadata_df.sort_values('firstn',axis=0, ascending=True)\n",
    "\n",
    "#looking at dates for unmatched images\n",
    "unmatched_image_df['date'] = unmatched_image_df['firstn'].str[:-5]\n",
    "unmatched_image_date_set= set(unmatched_image_df['date'])\n",
    "print(\"There are {0} days which have images with no accompanying metadata.\".format(len(unmatched_image_date_set)))\n",
    "\n",
    "#looking at dates for metadata files\n",
    "sorted_metadata_df['date'] = sorted_metadata_df['firstn'].str[:-5]\n",
    "metadata_date_set = set(sorted_metadata_df['date'])\n",
    "print(\"There are {0} days with at least one metadata file.\".format(len(metadata_date_set)))\n",
    "\n",
    "#Checking the overlap of days\n",
    "both_dates = metadata_date_set.intersection(unmatched_image_date_set)\n",
    "print(\"There are {0} days which overlap between metadata file coverage and unmatched images.\".format(len(both_dates)))\n",
    "\n",
    "\n",
    "#Understanding the range of days\n",
    "print(\"The unmatched image file dates range from {0} to {1}.\".format(min(unmatched_image_date_set), max(unmatched_image_date_set)))\n",
    "print(\"The metadata file dates range from {0} to {1}.\".format(min(metadata_date_set), max(metadata_date_set)))\n",
    "#print(sorted(metadata_date_set))\n",
    "#print(sorted(unmatched_image_date_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c2e786",
   "metadata": {},
   "source": [
    "It would be nice to ask Chris for the missing metadata files so we can tie them back to the wav files processed by VGGish. To quantify what we are missing, how many annotations do we have vs. not have in each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "03ed5a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of annotated sounds by matched metadata status is as follows:\n",
      "matched_metadata  sound        \n",
      "0                 airplane           18\n",
      "                  boat                8\n",
      "                  fish               21\n",
      "                  flow noise        471\n",
      "                  helicopter          8\n",
      "                  humpback         1130\n",
      "                  mooring            56\n",
      "1                 airplane           14\n",
      "                  fish               67\n",
      "                  flow noise        345\n",
      "                  helicopter         15\n",
      "                  humpback          391\n",
      "                  mooring           405\n",
      "                  mooring noise       3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Define function with matching\n",
    "def label_matches(row):\n",
    "    if row['filename'] == None:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "#Apply that function to the df\n",
    "meta_annotation_df['matched_metadata'] = meta_annotation_df.apply(label_matches, axis = 1)\n",
    "meta_annotation_df\n",
    "\n",
    "#Grouping annotations by metadata matched vs. not matched\n",
    "print(\"The distribution of annotated sounds by matched metadata status is as follows:\")\n",
    "print(meta_annotation_df.groupby(['matched_metadata','sound']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ec1a9352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of unique images by matched metadata status is as follows:\n",
      "matched_metadata\n",
      "0    187\n",
      "1    222\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#meta_annotation_df['image_name'].groupby(['matched_metadata', 'image_name']).size()\n",
    "images_matching_status = meta_annotation_df[['image_name', 'matched_metadata']].drop_duplicates()\n",
    "\n",
    "print(\"The distribution of unique images by matched metadata status is as follows:\")\n",
    "print(images_matching_status.groupby('matched_metadata').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35204e19",
   "metadata": {},
   "source": [
    "We have 187 images which we don't have metadata for. What if we could still map them back to the wav files using the date and time?\n",
    "\n",
    "    image_name: 20181204T100004-File-0.png\n",
    "    Hydrophone recording name: 181204-100002-437599-806141979.wav\n",
    "\n",
    "For the missing images we need to reformat their names into YYMMDD-HHMMSS and see how many .wav files we can match back to them - ideally 1 wav file per spectrogram. There may be multiple spectrogram per wav as would be expected given wav files represent ~30 min of audio, and each spectrogram contains 1 min of audio. We will do this similarly to the matching process above via tables. We begin by creating a table of all the wav file info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "24fb7868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a df with all the wav file name info\n",
    "wav_df = pd.DataFrame(columns=['wav_name','firstn'])\n",
    "\n",
    "#Populating the wav_df\n",
    "hd_path = 'D:/1Dec2018_28Feb2019/Hydrophone'\n",
    "all_wav_files = [file for file in listdir(hd_path) if isfile(join(hd_path, file))]\n",
    "for file in all_wav_files:\n",
    "    wav_df.loc[len(wav_df.index)] = [file, file[:13]]\n",
    "\n",
    "#Saving wav_df\n",
    "wav_df.to_csv('all_wav_file_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a4d9d770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately no wav files matched back to the previously unmatched images on YYMMDD-HHMMSS\n"
     ]
    }
   ],
   "source": [
    "#Opening the unmatched_image and all_metadata_file csvs created earlier so we don't have to remake them\n",
    "unmatched_image_df = pd.read_csv('unmatched_image_info.csv')\n",
    "metadata_df = pd.read_csv('all_metadata_file_info.csv')\n",
    "wav_df = pd.read_csv('all_wav_file_info.csv')\n",
    "\n",
    "#Extracting the image information in a way that is useful for matching to wav files\n",
    "unmatched_image_df['wav_format'] = unmatched_image_df['image_name'].str[2:8]+'-'+unmatched_image_df['image_name'].str[9:15]\n",
    "\n",
    "#Attempting to left join the wav filenames onto the missing image wav_formats to see how many matches there are\n",
    "image_to_wav_df = pd.merge(left=unmatched_image_df, right = wav_df, how='left', left_on='wav_format', right_on='firstn')\n",
    "if len(image_to_wav_df.loc[image_to_wav_df['wav_name'].notna()]) > 0:\n",
    "    print(\"Some wav files matched back to the images based on YYMMDD-HHMMSS\")\n",
    "else:\n",
    "    print(\"Unfortunately no wav files matched back to the previously unmatched images on YYMMDD-HHMMSS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d1cd6",
   "metadata": {},
   "source": [
    "Perhaps we have an issue in dates or times specifically. What if we try to match back on only 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "51b49339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matches between unmatches images and wav files based on dates & times\n",
      "**There were matches between unmatched images and wav files based on dates alone\n",
      "No matches between unmatches images and wav files based on times alone\n"
     ]
    }
   ],
   "source": [
    "#Getting image dates in wav format\n",
    "unmatched_image_df['wav_dates'] = unmatched_image_df['wav_format'].str[:6]\n",
    "unmatched_image_df['wav_times'] = unmatched_image_df['wav_format'].str[7:]\n",
    "\n",
    "#Getting dates out of wav names\n",
    "wav_df['wav_dates'] = wav_df['firstn'].str[:6]\n",
    "wav_df['wav_times'] = wav_df['firstn'].str[7:]\n",
    "\n",
    "#Matching back wav to images based on dates and times\n",
    "image_to_wav_all_df = pd.merge(left=unmatched_image_df, right=wav_df, how='left',\n",
    "                                on=['wav_dates','wav_times'], suffixes=['_image', '_wav'])\n",
    "if len(image_to_wav_all_df[image_to_wav_all_df['wav_name'].notna()]) > 0:\n",
    "    print(\"**There were matches between unmatched images and wav files based on dates & times\")\n",
    "    #print(image_to_wav_all_df.head())\n",
    "else:\n",
    "    print(\"No matches between unmatches images and wav files based on dates & times\")\n",
    "    \n",
    "#Matching back wav to images based on dates alone\n",
    "image_to_wav_dates_df = pd.merge(left=unmatched_image_df, right=wav_df, how='left',\n",
    "                                 on='wav_dates', suffixes=['_image', '_wav'])\n",
    "if len(image_to_wav_dates_df[image_to_wav_dates_df['wav_name'].notna()]) > 0:\n",
    "    print(\"**There were matches between unmatched images and wav files based on dates alone\")\n",
    "    #print(image_to_wav_dates_df.head())\n",
    "else:\n",
    "    print(\"No matches between unmatches images and wav files based on dates alone\")\n",
    "\n",
    "#Matching back wav to images based on times alone\n",
    "image_to_wav_times_df = pd.merge(left=unmatched_image_df, right=wav_df, how='left',\n",
    "                                 on='wav_times', suffixes=['_image', '_wav'])\n",
    "if len(image_to_wav_times_df[image_to_wav_times_df['wav_name'].notna()]) > 0:\n",
    "    print(\"**There were matches between unmatched images and wav files based on times alone\")\n",
    "    #print(image_to_wav_times_df.head())\n",
    "else:\n",
    "    print(\"No matches between unmatches images and wav files based on times alone\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a351a",
   "metadata": {},
   "source": [
    "Based on the above analysis we can see that there are matching dates, but not times. There was an issue in Chris' original file creation where some '4' in the seconds were accidentally transcribed as '2' (or perhaps it was the reverse). If in the joined image/wav df if one set of wav_times ends with only 4s and the other ends with only 2s we can probably assume this was the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "93d27fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mismatch between wav and images when using YYYYMMDD-HHMMSS appears to be the last digit of seconds.\n",
      "The last digit(s) of image times is(are) ['4'] when all else in YYYYMMDD-HHMMSS matches.\n",
      "The last digit(s) of wav times is(are) ['2'] when all else in YYYYMMDD-HHMMSS matches.\n",
      "The 2/4 issue appears to blame.\n"
     ]
    }
   ],
   "source": [
    "#How many wav align to each image? Appears to be 16 wav/image\n",
    "wav_per_image = image_to_wav_dates_df.groupby('image_name').count().reset_index()\n",
    "#print(wav_per_image[wav_per_image['firstn_image']!= 16])\n",
    "\n",
    "#How many time stamps of wavs are there - did they run continuously or in 16 consistent increments?\n",
    "#print(\"Wav data seems to have been taken {0} times per day\".format(len(image_to_wav_dates_df['wav_times_wav'].unique())))\n",
    "\n",
    "#Seeing if we can filter the image_to_wav_dates_df to where the HHMMS match\n",
    "image_wav_mostly_times = image_to_wav_dates_df[image_to_wav_dates_df['wav_times_image'].str[:5] == image_to_wav_dates_df['wav_times_wav'].str[:5]]\n",
    "\n",
    "#Do we have 187 rows if we filter where the HHMMs match?\n",
    "if len(image_wav_mostly_times) == 187:\n",
    "    print(\"The mismatch between wav and images when using YYYYMMDD-HHMMSS appears to be the last digit of seconds.\")\n",
    "    print(\"The last digit(s) of image times is(are) {0} when all else in YYYYMMDD-HHMMSS matches.\".format(list(image_wav_mostly_times['wav_times_image'].str[-1:].unique())))\n",
    "    print(\"The last digit(s) of wav times is(are) {0} when all else in YYYYMMDD-HHMMSS matches.\".format(list(image_wav_mostly_times['wav_times_wav'].str[-1:].unique())))\n",
    "    if ((list(image_wav_mostly_times['wav_times_wav'].str[-1:].unique())[0]== '2') and \n",
    "        (list(image_wav_mostly_times['wav_times_image'].str[-1:].unique())[0] == '4')):\n",
    "        print(\"The 2/4 issue appears to blame.\")\n",
    "else:\n",
    "    print(\"The mismatch between wav and images isn't entirely due to the last digit of seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b1754",
   "metadata": {},
   "source": [
    "We've figured out how to match back wav files to the unannotated images based on the image/wav files' dates (YYMMDD) and times minus the single seconds (HHMMS). Now let's merge the outputs of the matched wav files back in with the rest of the annotations in meta_annotation_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8e3de81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good merge - every previously unmatched image now has an associated wav file\n",
      "Cleaning up the resulting table.\n"
     ]
    }
   ],
   "source": [
    "#Merging image_wav_mostly_times back into the big meta_annotation_df\n",
    "wav_meta_annotation_df = pd.merge(left = meta_annotation_df, right= image_wav_mostly_times[['image_name','wav_name']],\n",
    "                                  how='left', on='image_name')\n",
    "if len(wav_meta_annotation_df.loc[wav_meta_annotation_df['wav_filename'].notnull() & wav_meta_annotation_df['wav_name'].notnull()]) > 0:\n",
    "    print(\"ERROR - some previously matched files have new wav file names appended which they shouldn't\")\n",
    "elif len(wav_meta_annotation_df.loc[wav_meta_annotation_df['wav_filename'].isnull() & wav_meta_annotation_df['wav_name'].isnull()]) > 0:\n",
    "    print(\"ERROR - some previously unmatched files have no new wav file names appended which is wrong\")\n",
    "elif len(wav_meta_annotation_df.loc[wav_meta_annotation_df['wav_filename'].isnull() & wav_meta_annotation_df['wav_name'].notnull()]['image_name'].unique()) == 187:\n",
    "    print(\"Good merge - every previously unmatched image now has an associated wav file\")\n",
    "    print(\"Cleaning up the resulting table.\")\n",
    "    wav_meta_annotation_df.loc[wav_meta_annotation_df[\"wav_filename\"].isnull(), \"wav_filename\"] = \"D:/1Dec2018_28Feb2019/Hydrophone/\"+wav_meta_annotation_df[\"wav_name\"]\n",
    "    wav_meta_annotation_df = wav_meta_annotation_df.drop('wav_name', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18af702",
   "metadata": {},
   "source": [
    "Let's see how many unique wav have been matched to images. We know it will be much less than the number of wav files we have because each wav generates 30 spectrograms and not each one was annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "689a0fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325 wav files in the hard drive, only 290 in the wav_meta_annotation_df.\n",
      "There are 290 unique wav files in the dataframe\n"
     ]
    }
   ],
   "source": [
    "#Testing to see if all wav files have been accounted for in the wav_meta_annotation_df\n",
    "\n",
    "#Getting list of wav files from hard drive\n",
    "wav_list = [file for file in os.listdir('D:/1Dec2018_28Feb2019/Hydrophone/') if file.endswith('.wav')]\n",
    "\n",
    "#List of wav files from meta_annotation_df\n",
    "matched_wav_list = list(wav_meta_annotation_df['wav_filename'].unique())\n",
    "\n",
    "if len(wav_list) != len(matched_wav_list):\n",
    "    print(\"{0} wav files in the hard drive, only {1} in the wav_meta_annotation_df.\".format(len(wav_list), len(matched_wav_list)))\n",
    "    print(\"There are {0} unique wav files in the dataframe\".format(len(wav_meta_annotation_df['wav_filename'].unique())))\n",
    "else:\n",
    "    print(\"All wav files accounted for in wav_meta_annotation_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e91a0",
   "metadata": {},
   "source": [
    "Now that we have wav files mapped back to their annotations, we need to understand what time each annotation occurs. We do this to ultimately map back to our VGGish embeddings which occurr every 0.96 seconds. We start by translating the \"windows_plotted\" back into audio seconds. From Chris' README we know that:\n",
    "\n",
    "- Windows plotted: Tells which files from the audio file are plotted. If 20 Hz spectrograms and the first \n",
    "           minute of the file this would be 1-1201. If the second minute they would be 1202-1401 etc. \n",
    "           These were saved because it would be possible to closely map the time of a second from the\n",
    "           window number and file start time.\n",
    "\n",
    "Based on that information we can surmise that 1 minute of audio = 1200 windows. We need to get the start and end number of windows, subtract them, and divide by 1200 to understand how much time is covered by each spectrogram. In the next block of code we will look at the annotation coordinates to find the more granular location in time from the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "17e6dbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound</th>\n",
       "      <th>points</th>\n",
       "      <th>image_name</th>\n",
       "      <th>json_file_path</th>\n",
       "      <th>metadata_file_path</th>\n",
       "      <th>filename</th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>windows_plotted</th>\n",
       "      <th>matched_metadata</th>\n",
       "      <th>spectrogram_start_time_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[382.56626506024094, 614.4819277108433], [458...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "      <td>181204-100002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...</td>\n",
       "      <td>9602-10801</td>\n",
       "      <td>1</td>\n",
       "      <td>480.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>helicopter</td>\n",
       "      <td>[[1920.952380952381, 1048.1904761904761], [216...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "      <td>181204-100002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...</td>\n",
       "      <td>9602-10801</td>\n",
       "      <td>1</td>\n",
       "      <td>480.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[424.7349397590361, 748.2168674698794], [490....</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>19202-20401</td>\n",
       "      <td>1</td>\n",
       "      <td>960.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1209.0722891566263, 938.5783132530119], [127...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>19202-20401</td>\n",
       "      <td>1</td>\n",
       "      <td>960.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1645.2168674698794, 744.6024096385541], [173...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>19202-20401</td>\n",
       "      <td>1</td>\n",
       "      <td>960.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>humpback</td>\n",
       "      <td>[[1548.1081081081081, 589.2432432432432], [161...</td>\n",
       "      <td>20190217T023004-File-27.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...</td>\n",
       "      <td>None</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>humpback</td>\n",
       "      <td>[[1637.2972972972973, 600.0540540540541], [166...</td>\n",
       "      <td>20190217T023004-File-27.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...</td>\n",
       "      <td>None</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>humpback</td>\n",
       "      <td>[[1892.7027027027027, 827.081081081081], [1933...</td>\n",
       "      <td>20190217T023004-File-27.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...</td>\n",
       "      <td>None</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>humpback</td>\n",
       "      <td>[[2044.0540540540542, 798.7027027027027], [208...</td>\n",
       "      <td>20190217T023004-File-27.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...</td>\n",
       "      <td>None</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>humpback</td>\n",
       "      <td>[[328.09523809523813, 514.8571428571429], [382...</td>\n",
       "      <td>20190217T023004-File-27.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...</td>\n",
       "      <td>None</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2959 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sound                                             points  \\\n",
       "0        mooring  [[382.56626506024094, 614.4819277108433], [458...   \n",
       "1     helicopter  [[1920.952380952381, 1048.1904761904761], [216...   \n",
       "2        mooring  [[424.7349397590361, 748.2168674698794], [490....   \n",
       "3        mooring  [[1209.0722891566263, 938.5783132530119], [127...   \n",
       "4        mooring  [[1645.2168674698794, 744.6024096385541], [173...   \n",
       "...          ...                                                ...   \n",
       "2954    humpback  [[1548.1081081081081, 589.2432432432432], [161...   \n",
       "2955    humpback  [[1637.2972972972973, 600.0540540540541], [166...   \n",
       "2956    humpback  [[1892.7027027027027, 827.081081081081], [1933...   \n",
       "2957    humpback  [[2044.0540540540542, 798.7027027027027], [208...   \n",
       "2958    humpback  [[328.09523809523813, 514.8571428571429], [382...   \n",
       "\n",
       "                       image_name  \\\n",
       "0      20181204T100004-File-8.png   \n",
       "1      20181204T100004-File-8.png   \n",
       "2     20181204T113004-File-16.png   \n",
       "3     20181204T113004-File-16.png   \n",
       "4     20181204T113004-File-16.png   \n",
       "...                           ...   \n",
       "2954  20190217T023004-File-27.png   \n",
       "2955  20190217T023004-File-27.png   \n",
       "2956  20190217T023004-File-27.png   \n",
       "2957  20190217T023004-File-27.png   \n",
       "2958  20190217T023004-File-27.png   \n",
       "\n",
       "                                         json_file_path  \\\n",
       "0     D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "1     D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "2     D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "3     D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "4     D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "...                                                 ...   \n",
       "2954  D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...   \n",
       "2955  D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...   \n",
       "2956  D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...   \n",
       "2957  D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...   \n",
       "2958  D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...   \n",
       "\n",
       "                                     metadata_file_path  \\\n",
       "0     D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...   \n",
       "1     D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...   \n",
       "2     D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "3     D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "4     D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "...                                                 ...   \n",
       "2954  D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...   \n",
       "2955  D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...   \n",
       "2956  D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...   \n",
       "2957  D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...   \n",
       "2958  D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...   \n",
       "\n",
       "                                               filename  \\\n",
       "0     181204-100002-437599-806141979_Spectrograms_20...   \n",
       "1     181204-100002-437599-806141979_Spectrograms_20...   \n",
       "2     181204-113002-437599-806141979_Spectrograms_20...   \n",
       "3     181204-113002-437599-806141979_Spectrograms_20...   \n",
       "4     181204-113002-437599-806141979_Spectrograms_20...   \n",
       "...                                                 ...   \n",
       "2954                                               None   \n",
       "2955                                               None   \n",
       "2956                                               None   \n",
       "2957                                               None   \n",
       "2958                                               None   \n",
       "\n",
       "                                           wav_filename windows_plotted  \\\n",
       "0     D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...      9602-10801   \n",
       "1     D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...      9602-10801   \n",
       "2     D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...     19202-20401   \n",
       "3     D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...     19202-20401   \n",
       "4     D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...     19202-20401   \n",
       "...                                                 ...             ...   \n",
       "2954  D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...            None   \n",
       "2955  D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...            None   \n",
       "2956  D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...            None   \n",
       "2957  D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...            None   \n",
       "2958  D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...            None   \n",
       "\n",
       "      matched_metadata  spectrogram_start_time_secs  \n",
       "0                    1                        480.1  \n",
       "1                    1                        480.1  \n",
       "2                    1                        960.1  \n",
       "3                    1                        960.1  \n",
       "4                    1                        960.1  \n",
       "...                ...                          ...  \n",
       "2954                 0                          NaN  \n",
       "2955                 0                          NaN  \n",
       "2956                 0                          NaN  \n",
       "2957                 0                          NaN  \n",
       "2958                 0                          NaN  \n",
       "\n",
       "[2959 rows x 10 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Breaking apart the windows_plotted into a start_window and stop_window\n",
    "wav_meta_annotation_df['start_window'] = wav_meta_annotation_df['windows_plotted'].str.split('-').str[0]\n",
    "wav_meta_annotation_df['start_window'] = pd.to_numeric(wav_meta_annotation_df['start_window'])\n",
    "\n",
    "#Time represented by spectrogram in minutes\n",
    "wav_meta_annotation_df['spectrogram_start_time_secs'] = (wav_meta_annotation_df['start_window']/1200)*60\n",
    "\n",
    "#Dropping the extra calculation columns\n",
    "wav_meta_annotation_df = wav_meta_annotation_df.drop(['start_window'], axis = 1)\n",
    "wav_meta_annotation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fbd806",
   "metadata": {},
   "source": [
    "In the next block of code we will create a column detailing the start and end time the annotated noise occurred. When added to the \"spectrogram_start_time\" measurement, it will tell us when in the audio file the annotation approximately occurred. Per Debbie, we know that the \"points\" are in the format [[x1, y1],[x2, y2]].\n",
    "\n",
    "We also know the points start at the upper left corner and the spectrogram starts at avg_left_edges: 309.532, min_left_edges: 306, max_left_edges: 314\n",
    "avg_right_edges: 2173.266, min_right_edges: 2167, max_right_edges: 2176.38\n",
    "\n",
    "Knowing each file is ~1 minute in length, by knowing the ratio of start (or end) pixel / total pixels * 60 seconds will give the additional time from the start of the spectrogram that the noise occurred (or stopped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "86310ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound</th>\n",
       "      <th>points</th>\n",
       "      <th>image_name</th>\n",
       "      <th>json_file_path</th>\n",
       "      <th>metadata_file_path</th>\n",
       "      <th>filename</th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>matched_metadata</th>\n",
       "      <th>time_in_wav_sound_start_sec</th>\n",
       "      <th>time_in_wav_sound_stop_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[382.56626506024094, 614.4819277108433], [458...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "      <td>181204-100002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...</td>\n",
       "      <td>1</td>\n",
       "      <td>482.451224</td>\n",
       "      <td>484.894822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>helicopter</td>\n",
       "      <td>[[1920.952380952381, 1048.1904761904761], [216...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "      <td>181204-100002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...</td>\n",
       "      <td>1</td>\n",
       "      <td>531.977158</td>\n",
       "      <td>539.872215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[424.7349397590361, 748.2168674698794], [490....</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>1</td>\n",
       "      <td>963.808778</td>\n",
       "      <td>965.942078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1209.0722891566263, 938.5783132530119], [127...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>1</td>\n",
       "      <td>989.059292</td>\n",
       "      <td>991.192592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1645.2168674698794, 744.6024096385541], [173...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>1</td>\n",
       "      <td>1003.100284</td>\n",
       "      <td>1006.009330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>humpback</td>\n",
       "      <td>[[1548.1081081081081, 589.2432432432432], [161...</td>\n",
       "      <td>20190217T023004-File-27.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...</td>\n",
       "      <td>None</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>humpback</td>\n",
       "      <td>[[1637.2972972972973, 600.0540540540541], [166...</td>\n",
       "      <td>20190217T023004-File-27.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...</td>\n",
       "      <td>None</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>humpback</td>\n",
       "      <td>[[1892.7027027027027, 827.081081081081], [1933...</td>\n",
       "      <td>20190217T023004-File-27.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...</td>\n",
       "      <td>None</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>humpback</td>\n",
       "      <td>[[2044.0540540540542, 798.7027027027027], [208...</td>\n",
       "      <td>20190217T023004-File-27.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...</td>\n",
       "      <td>None</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>humpback</td>\n",
       "      <td>[[328.09523809523813, 514.8571428571429], [382...</td>\n",
       "      <td>20190217T023004-File-27.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...</td>\n",
       "      <td>None</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2959 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sound                                             points  \\\n",
       "0        mooring  [[382.56626506024094, 614.4819277108433], [458...   \n",
       "1     helicopter  [[1920.952380952381, 1048.1904761904761], [216...   \n",
       "2        mooring  [[424.7349397590361, 748.2168674698794], [490....   \n",
       "3        mooring  [[1209.0722891566263, 938.5783132530119], [127...   \n",
       "4        mooring  [[1645.2168674698794, 744.6024096385541], [173...   \n",
       "...          ...                                                ...   \n",
       "2954    humpback  [[1548.1081081081081, 589.2432432432432], [161...   \n",
       "2955    humpback  [[1637.2972972972973, 600.0540540540541], [166...   \n",
       "2956    humpback  [[1892.7027027027027, 827.081081081081], [1933...   \n",
       "2957    humpback  [[2044.0540540540542, 798.7027027027027], [208...   \n",
       "2958    humpback  [[328.09523809523813, 514.8571428571429], [382...   \n",
       "\n",
       "                       image_name  \\\n",
       "0      20181204T100004-File-8.png   \n",
       "1      20181204T100004-File-8.png   \n",
       "2     20181204T113004-File-16.png   \n",
       "3     20181204T113004-File-16.png   \n",
       "4     20181204T113004-File-16.png   \n",
       "...                           ...   \n",
       "2954  20190217T023004-File-27.png   \n",
       "2955  20190217T023004-File-27.png   \n",
       "2956  20190217T023004-File-27.png   \n",
       "2957  20190217T023004-File-27.png   \n",
       "2958  20190217T023004-File-27.png   \n",
       "\n",
       "                                         json_file_path  \\\n",
       "0     D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "1     D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "2     D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "3     D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "4     D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "...                                                 ...   \n",
       "2954  D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...   \n",
       "2955  D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...   \n",
       "2956  D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...   \n",
       "2957  D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...   \n",
       "2958  D:/Annotation Stuff/MLFigsLabeled_Nov_09_Chris...   \n",
       "\n",
       "                                     metadata_file_path  \\\n",
       "0     D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...   \n",
       "1     D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...   \n",
       "2     D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "3     D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "4     D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "...                                                 ...   \n",
       "2954  D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...   \n",
       "2955  D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...   \n",
       "2956  D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...   \n",
       "2957  D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...   \n",
       "2958  D:/1Dec2018_28Feb2019/MLFigsMeta/20190217T0230...   \n",
       "\n",
       "                                               filename  \\\n",
       "0     181204-100002-437599-806141979_Spectrograms_20...   \n",
       "1     181204-100002-437599-806141979_Spectrograms_20...   \n",
       "2     181204-113002-437599-806141979_Spectrograms_20...   \n",
       "3     181204-113002-437599-806141979_Spectrograms_20...   \n",
       "4     181204-113002-437599-806141979_Spectrograms_20...   \n",
       "...                                                 ...   \n",
       "2954                                               None   \n",
       "2955                                               None   \n",
       "2956                                               None   \n",
       "2957                                               None   \n",
       "2958                                               None   \n",
       "\n",
       "                                           wav_filename  matched_metadata  \\\n",
       "0     D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...                 1   \n",
       "1     D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...                 1   \n",
       "2     D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...                 1   \n",
       "3     D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...                 1   \n",
       "4     D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...                 1   \n",
       "...                                                 ...               ...   \n",
       "2954  D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...                 0   \n",
       "2955  D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...                 0   \n",
       "2956  D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...                 0   \n",
       "2957  D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...                 0   \n",
       "2958  D:/1Dec2018_28Feb2019/Hydrophone/190217-023002...                 0   \n",
       "\n",
       "      time_in_wav_sound_start_sec  time_in_wav_sound_stop_sec  \n",
       "0                      482.451224                  484.894822  \n",
       "1                      531.977158                  539.872215  \n",
       "2                      963.808778                  965.942078  \n",
       "3                      989.059292                  991.192592  \n",
       "4                     1003.100284                 1006.009330  \n",
       "...                           ...                         ...  \n",
       "2954                          NaN                         NaN  \n",
       "2955                          NaN                         NaN  \n",
       "2956                          NaN                         NaN  \n",
       "2957                          NaN                         NaN  \n",
       "2958                          NaN                         NaN  \n",
       "\n",
       "[2959 rows x 10 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting individual points from points column\n",
    "wav_meta_annotation_df['point1'] = wav_meta_annotation_df['points'].str[0]\n",
    "wav_meta_annotation_df['point2'] = wav_meta_annotation_df['points'].str[1]\n",
    "\n",
    "#Getting x1 and x2 from point1 and point2\n",
    "wav_meta_annotation_df['x1'] = wav_meta_annotation_df['point1'].str[0]\n",
    "wav_meta_annotation_df['x2'] = wav_meta_annotation_df['point2'].str[0]\n",
    "\n",
    "#Finding the start vs. the stop time\n",
    "wav_meta_annotation_df['annotation_start'] = wav_meta_annotation_df[[\"x1\", \"x2\"]].min(axis=1)\n",
    "wav_meta_annotation_df['annotation_stop'] = wav_meta_annotation_df[[\"x1\", \"x2\"]].max(axis=1)\n",
    "\n",
    "#Subtract the left edge of the spectrogram from the start and stop times to get only the area in the spectrogram\n",
    "wav_meta_annotation_df['annotation_start'] = wav_meta_annotation_df['annotation_start'] - 309.532\n",
    "wav_meta_annotation_df['annotation_stop'] = wav_meta_annotation_df['annotation_stop'] - 309.532\n",
    "\n",
    "#Divide the start & stop times by the total pixels in the spectrogram () & multiply by 60 for sec\n",
    "wav_meta_annotation_df['annotation_start_sec'] = wav_meta_annotation_df['annotation_start'] * 60 / (2173.266- 309.532)\n",
    "wav_meta_annotation_df['annotation_stop_sec'] = wav_meta_annotation_df['annotation_stop'] * 60 / (2173.266- 309.532)\n",
    "\n",
    "#Adding the spectrogram_start_time_secs to annotation_start_sec to get the final annotation start/stop time\n",
    "wav_meta_annotation_df['time_in_wav_sound_start_sec'] = wav_meta_annotation_df['annotation_start_sec'] + wav_meta_annotation_df['spectrogram_start_time_secs']\n",
    "wav_meta_annotation_df['time_in_wav_sound_stop_sec'] = wav_meta_annotation_df['annotation_stop_sec'] + wav_meta_annotation_df['spectrogram_start_time_secs']\n",
    "\n",
    "#Removing all the calculation columns\n",
    "wav_meta_annotation_df = wav_meta_annotation_df.drop(['windows_plotted','spectrogram_start_time_secs','point1','point2','x1','x2','annotation_start','annotation_stop','annotation_start_sec','annotation_stop_sec'], axis=1)\n",
    "wav_meta_annotation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f241133",
   "metadata": {},
   "source": [
    "Now that we know when each annotation occurred in the wav file, we can match back to the ~1800 slices created by VGGish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "f7a8c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a col with the start image slice and the end image slice by dividing the time by 0.96 for the seconds in the spectrogram\n",
    "wav_meta_annotation_df['start_slice'] = wav_meta_annotation_df['time_in_wav_sound_start_sec'] / 0.96\n",
    "wav_meta_annotation_df['stop_slice'] = wav_meta_annotation_df['time_in_wav_sound_stop_sec'] / 0.96\n",
    "\n",
    "#Taking the floor of the start slice and the ceiling of the stop slice to ensure we get all the sound\n",
    "wav_meta_annotation_df['start_slice'] = wav_meta_annotation_df['start_slice'].apply(np.floor)\n",
    "wav_meta_annotation_df['stop_slice'] = wav_meta_annotation_df['stop_slice'].apply(np.ceil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e9db1",
   "metadata": {},
   "source": [
    "Now we need to match the image slices to each file. We have the slices already in start_slice and stop_slice. We also need to match back to the file number using the lookup table Saumya wrote. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb35e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1f07721",
   "metadata": {},
   "source": [
    "Finally, we save the final output as wav_to_annotations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "3ac0724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving wav to annotation information for future use\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound</th>\n",
       "      <th>points</th>\n",
       "      <th>image_name</th>\n",
       "      <th>json_file_path</th>\n",
       "      <th>metadata_file_path</th>\n",
       "      <th>filename</th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>matched_metadata</th>\n",
       "      <th>time_in_wav_sound_start_sec</th>\n",
       "      <th>time_in_wav_sound_stop_sec</th>\n",
       "      <th>start_slice</th>\n",
       "      <th>stop_slice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[382.56626506024094, 614.4819277108433], [458...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "      <td>181204-100002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...</td>\n",
       "      <td>1</td>\n",
       "      <td>482.451224</td>\n",
       "      <td>484.894822</td>\n",
       "      <td>502.0</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>helicopter</td>\n",
       "      <td>[[1920.952380952381, 1048.1904761904761], [216...</td>\n",
       "      <td>20181204T100004-File-8.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...</td>\n",
       "      <td>181204-100002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...</td>\n",
       "      <td>1</td>\n",
       "      <td>531.977158</td>\n",
       "      <td>539.872215</td>\n",
       "      <td>554.0</td>\n",
       "      <td>563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[424.7349397590361, 748.2168674698794], [490....</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>1</td>\n",
       "      <td>963.808778</td>\n",
       "      <td>965.942078</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1209.0722891566263, 938.5783132530119], [127...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>1</td>\n",
       "      <td>989.059292</td>\n",
       "      <td>991.192592</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1033.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mooring</td>\n",
       "      <td>[[1645.2168674698794, 744.6024096385541], [173...</td>\n",
       "      <td>20181204T113004-File-16.png</td>\n",
       "      <td>D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...</td>\n",
       "      <td>181204-113002-437599-806141979_Spectrograms_20...</td>\n",
       "      <td>D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...</td>\n",
       "      <td>1</td>\n",
       "      <td>1003.100284</td>\n",
       "      <td>1006.009330</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>1048.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sound                                             points  \\\n",
       "0     mooring  [[382.56626506024094, 614.4819277108433], [458...   \n",
       "1  helicopter  [[1920.952380952381, 1048.1904761904761], [216...   \n",
       "2     mooring  [[424.7349397590361, 748.2168674698794], [490....   \n",
       "3     mooring  [[1209.0722891566263, 938.5783132530119], [127...   \n",
       "4     mooring  [[1645.2168674698794, 744.6024096385541], [173...   \n",
       "\n",
       "                    image_name  \\\n",
       "0   20181204T100004-File-8.png   \n",
       "1   20181204T100004-File-8.png   \n",
       "2  20181204T113004-File-16.png   \n",
       "3  20181204T113004-File-16.png   \n",
       "4  20181204T113004-File-16.png   \n",
       "\n",
       "                                      json_file_path  \\\n",
       "0  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "1  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "2  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "3  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "4  D:/Annotation Stuff/MLFigs_Labeled_Oct_26_Chri...   \n",
       "\n",
       "                                  metadata_file_path  \\\n",
       "0  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...   \n",
       "1  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1000...   \n",
       "2  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "3  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "4  D:/1Dec2018_28Feb2019/MLFigsMeta/20181204T1130...   \n",
       "\n",
       "                                            filename  \\\n",
       "0  181204-100002-437599-806141979_Spectrograms_20...   \n",
       "1  181204-100002-437599-806141979_Spectrograms_20...   \n",
       "2  181204-113002-437599-806141979_Spectrograms_20...   \n",
       "3  181204-113002-437599-806141979_Spectrograms_20...   \n",
       "4  181204-113002-437599-806141979_Spectrograms_20...   \n",
       "\n",
       "                                        wav_filename  matched_metadata  \\\n",
       "0  D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...                 1   \n",
       "1  D:/1Dec2018_28Feb2019/Hydrophone/181204-100002...                 1   \n",
       "2  D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...                 1   \n",
       "3  D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...                 1   \n",
       "4  D:/1Dec2018_28Feb2019/Hydrophone/181204-113002...                 1   \n",
       "\n",
       "   time_in_wav_sound_start_sec  time_in_wav_sound_stop_sec  start_slice  \\\n",
       "0                   482.451224                  484.894822        502.0   \n",
       "1                   531.977158                  539.872215        554.0   \n",
       "2                   963.808778                  965.942078       1003.0   \n",
       "3                   989.059292                  991.192592       1030.0   \n",
       "4                  1003.100284                 1006.009330       1044.0   \n",
       "\n",
       "   stop_slice  \n",
       "0       506.0  \n",
       "1       563.0  \n",
       "2      1007.0  \n",
       "3      1033.0  \n",
       "4      1048.0  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the file\n",
    "print('Saving wav to annotation information for future use')\n",
    "wav_meta_annotation_df.to_csv('wav_to_annotation.csv')\n",
    "wav_meta_annotation_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
